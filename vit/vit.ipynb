{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## OverView\n",
    "In this guide, we show how to enable PyTorch model with OpenVINO, and how to optimize Vision Transformers models with quantize."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setup Development Environment\n",
    "2. Convert the PyTorch model to ONNX model\n",
    "3. Apply Bf16 quantization using OpenVINO\n",
    "3. Apply Int8 quantization using OpenVINO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Development Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 1)) (1.13.0)\n",
      "Requirement already satisfied: transformers in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 2)) (4.26.1)\n",
      "Requirement already satisfied: datasets in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 3)) (2.9.0)\n",
      "Requirement already satisfied: Pillow in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 4)) (9.4.0)\n",
      "Requirement already satisfied: numpy in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 5)) (1.23.4)\n",
      "Requirement already satisfied: intel-extension-for-pytorch==1.13.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 7)) (1.13.0)\n",
      "Requirement already satisfied: onnxruntime in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 8)) (1.14.0)\n",
      "Requirement already satisfied: openvino-dev[ONNX,pytorch]==2022.3.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 9)) (2022.3.0)\n",
      "Requirement already satisfied: torch_tb_profiler in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 10)) (0.4.1)\n",
      "Requirement already satisfied: matplotlib in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 11)) (3.7.1)\n",
      "Requirement already satisfied: psutil in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from intel-extension-for-pytorch==1.13.0->-r ../requirements.txt (line 7)) (5.9.4)\n",
      "Requirement already satisfied: jstyleson>=0.0.2 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (0.0.2)\n",
      "Requirement already satisfied: openvino-telemetry>=2022.1.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (2022.3.0)\n",
      "Requirement already satisfied: openvino==2022.3.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (2022.3.0)\n",
      "Requirement already satisfied: pandas~=1.3.5 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.25.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (2.28.2)\n",
      "Requirement already satisfied: texttable>=1.6.3 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (1.6.7)\n",
      "Requirement already satisfied: tqdm>=4.54.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (6.0)\n",
      "Requirement already satisfied: scipy>=1.8 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (1.8.1)\n",
      "Requirement already satisfied: opencv-python>=4.5 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (4.7.0.68)\n",
      "Requirement already satisfied: networkx<=2.8.8 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (2.8.8)\n",
      "Requirement already satisfied: addict>=2.4.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (2.4.0)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (0.7.1)\n",
      "Requirement already satisfied: fastjsonschema~=2.15.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (2.15.3)\n",
      "Requirement already satisfied: onnx<=1.12,>=1.8.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (1.12.0)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.18.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (3.19.6)\n",
      "Requirement already satisfied: torchvision<=0.14.0,>=0.9.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (0.14.0)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (0.1.8)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from torch->-r ../requirements.txt (line 1)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from torch->-r ../requirements.txt (line 1)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from torch->-r ../requirements.txt (line 1)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from torch->-r ../requirements.txt (line 1)) (8.5.0.96)\n",
      "Requirement already satisfied: typing-extensions in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from torch->-r ../requirements.txt (line 1)) (4.4.0)\n",
      "Requirement already satisfied: setuptools in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r ../requirements.txt (line 1)) (65.5.0)\n",
      "Requirement already satisfied: wheel in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r ../requirements.txt (line 1)) (0.37.1)\n",
      "Requirement already satisfied: filelock in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 2)) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 2)) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 2)) (2022.10.31)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 2)) (0.13.2)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 3)) (11.0.0)\n",
      "Requirement already satisfied: multiprocess in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 3)) (0.70.14)\n",
      "Requirement already satisfied: dill<0.3.7 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 3)) (0.3.6)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 3)) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 3)) (3.8.4)\n",
      "Requirement already satisfied: responses<0.19 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 3)) (0.18.0)\n",
      "Requirement already satisfied: xxhash in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: sympy in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from onnxruntime->-r ../requirements.txt (line 8)) (1.11.1)\n",
      "Requirement already satisfied: flatbuffers in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from onnxruntime->-r ../requirements.txt (line 8)) (23.1.21)\n",
      "Requirement already satisfied: coloredlogs in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from onnxruntime->-r ../requirements.txt (line 8)) (15.0.1)\n",
      "Requirement already satisfied: tensorboard!=2.1.0,>=1.15 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from torch_tb_profiler->-r ../requirements.txt (line 10)) (2.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 11)) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 11)) (1.0.7)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 11)) (5.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 11)) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 11)) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 11)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 11)) (2.8.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 3)) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 3)) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 3)) (2.1.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 3)) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 3)) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 3)) (22.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->-r ../requirements.txt (line 11)) (3.14.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from pandas~=1.3.5->openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->-r ../requirements.txt (line 11)) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from requests>=2.25.1->openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from requests>=2.25.1->openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from requests>=2.25.1->openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (2022.12.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (2.1.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (1.42.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (1.4.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (2.16.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (1.8.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from coloredlogs->onnxruntime->-r ../requirements.txt (line 8)) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from sympy->onnxruntime->-r ../requirements.txt (line 8)) (1.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (6.0.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Pytorch model to ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/transformers/models/vit/modeling_vit.py:165: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if num_channels != self.num_channels:\n",
      "/home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/transformers/models/vit/modeling_vit.py:170: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if height != self.image_size[0] or width != self.image_size[1]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert success!\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "url = 'https://datasets-server.huggingface.co/assets/beans/--/default/validation/30/image/image.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "model_id=\"nateraw/vit-base-beans\"\n",
    "model_name=\"vit-base-beans\"\n",
    "onnx_path = Path(\"onnx\")\n",
    "\n",
    "image_processor = ViTImageProcessor.from_pretrained(model_id)\n",
    "model = ViTForImageClassification.from_pretrained(model_id)\n",
    "\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# print(model(**inputs))\n",
    "\n",
    "torch.onnx.export(model, inputs[\"pixel_values\"], model_name+'.onnx',\n",
    "    input_names=[\"input\"], output_names=[\"output\"],\n",
    "    dynamic_axes={'input': {0:'batch'}, 'output': {0:'batch'}})\n",
    "\n",
    "print(\"Convert success!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Bf16 quantization using OpenVINO\n",
    "\n",
    "### Test the performance (latency) of quantized model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark with models:\n",
      "fp32_model: P95 latency (ms) - 16.660605580545962; Average latency (ms) - 15.12 +\\- 1.59;\n",
      "bf16_model: P95 latency (ms) - 8.549499016953632; Average latency (ms) - 8.00 +\\- 1.64;\n",
      "Improvement through quantization: 1.95x\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import openvino.runtime as ov\n",
    "from time import perf_counter\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from datasets import load_dataset\n",
    "\n",
    "payload=\"https://datasets-server.huggingface.co/assets/beans/--/default/validation/30/image/image.jpg\"\n",
    "image = Image.open(requests.get(payload, stream=True).raw)\n",
    "\n",
    "def measure_latency(model, inputs):\n",
    "    # prepare date\n",
    "    latencies = []\n",
    "    # warm up\n",
    "    for _ in range(10):\n",
    "        _ = model(inputs)\n",
    "    # Timed run\n",
    "    for _ in range(1000):\n",
    "        start_time = perf_counter()\n",
    "        _ = model(inputs)\n",
    "        latency = perf_counter() - start_time\n",
    "        latencies.append(latency)\n",
    "    # Compute run statistics\n",
    "    time_avg_ms = 1000 * np.mean(latencies)\n",
    "    time_std_ms = 1000 * np.std(latencies)\n",
    "    time_p95_ms = 1000 * np.percentile(latencies,95)\n",
    "    return f\"P95 latency (ms) - {time_p95_ms}; Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f};\", time_p95_ms\n",
    "\n",
    "core = ov.Core()\n",
    "core.set_property(\"CPU\", {\"INFERENCE_PRECISION_HINT\": \"f32\"})\n",
    "fp32_model = core.compile_model(model_name+'.onnx', \"AUTO\")\n",
    "\n",
    "core.set_property(\"CPU\", {\"INFERENCE_PRECISION_HINT\": \"bf16\"})\n",
    "bf16_model = core.compile_model(model_name+'.onnx', \"AUTO\")\n",
    "\n",
    "inputs = image_processor(image, return_tensors=\"pt\")\n",
    "# Create tensor from external memory\n",
    "ov_inputs=inputs[\"pixel_values\"].numpy()\n",
    "input_tensor = ov.Tensor(array=ov_inputs, shape=[1, 3, 224, 224])\n",
    "\n",
    "print(f\"benchmark with models:\")\n",
    "rtn_fp32_model = measure_latency(fp32_model, input_tensor)\n",
    "rtn_bf16_model = measure_latency(bf16_model, input_tensor)\n",
    "\n",
    "print(f\"fp32_model: {rtn_fp32_model[0]}\")\n",
    "print(f\"bf16_model: {rtn_bf16_model[0]}\")\n",
    "print(f\"Improvement through quantization: {round(rtn_fp32_model[1]/rtn_bf16_model[1], 2)}x\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the accuraccy of quantized model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset beans (/home/marvin/.cache/huggingface/datasets/beans/default/0.0.0/90c755fb6db1c0ccdad02e897a37969dbf070bed3755d4391e269ff70642d791)\n",
      "100%|██████████| 1/1 [00:00<00:00, 725.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp32_accuracy: 96.88%\n",
      "bf16_accuracy: 96.88%\n",
      "The quantized model achieves 100.00% accuracy of the fp32 model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "eval_dataset = load_dataset(\"beans\",split=[\"test\"])[0]\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    return dict(accuracy=accuracy_score(predictions, labels))\n",
    "\n",
    "def predict(model, image):\n",
    "    inputs = image_processor(image, return_tensors=\"pt\")\n",
    "    ov_inputs=inputs[\"pixel_values\"].numpy()\n",
    "    input_tensor = ov.Tensor(array=ov_inputs, shape=[1, 3, 224, 224])\n",
    "    return model(input_tensor)\n",
    "\n",
    "size = len(eval_dataset[\"image\"])\n",
    "\n",
    "fp32_eval_pred = ([predict(fp32_model, eval_dataset[\"image\"][i])[fp32_model.output(0)] for i in range(size)], eval_dataset[\"labels\"])\n",
    "bf16_eval_pred = ([predict(bf16_model, eval_dataset[\"image\"][i])[bf16_model.output(0)] for i in range(size)], eval_dataset[\"labels\"])\n",
    "\n",
    "fp32_accuracy = compute_metrics(fp32_eval_pred)\n",
    "bf16_accuracy = compute_metrics(bf16_eval_pred)\n",
    "\n",
    "print(f\"fp32_accuracy: {fp32_accuracy['accuracy']*100:.2f}%\")\n",
    "print(f\"bf16_accuracy: {bf16_accuracy['accuracy']*100:.2f}%\")\n",
    "print(f\"The quantized model achieves {round(bf16_accuracy['accuracy']/fp32_accuracy['accuracy'],4)*100:.2f}% accuracy of the fp32 model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Int8 quantization using OpenVINO\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the calibration dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from openvino.runtime import Core, Tensor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set the data and model directories\n",
    "MODEL_DIR = 'model'\n",
    "CALIB_DIR = 'calib'\n",
    "CIFAR_DIR = 'data/datasets/beans'\n",
    "CALIB_SET_SIZE = 300\n",
    "MODEL_NAME = 'vit-base-beans'\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(CALIB_DIR, exist_ok=True)\n",
    "os.makedirs(CIFAR_DIR, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downlaod the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset beans (/home/marvin/.cache/huggingface/datasets/beans/default/0.0.0/90c755fb6db1c0ccdad02e897a37969dbf070bed3755d4391e269ff70642d791)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1218.92it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset('beans')['train']\n",
    "lbs = ds['labels']\n",
    "\n",
    "_index = 0\n",
    "_label_index = [100, 100, 100]\n",
    "\n",
    "for idx, info in enumerate(ds):\n",
    "    im = info[\"image\"]\n",
    "    label = info[\"labels\"]\n",
    "    if _label_index[label] > 0:\n",
    "        im = im.resize((224, 224))\n",
    "        im.save(Path(CALIB_DIR) / f'{label}_{_index}.jpg')\n",
    "        _label_index[label] = _label_index[label] - 1\n",
    "        _index = _index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_path = Path(\".\") / 'vit-base-beans.onnx'\n",
    "ir_model_xml = Path(MODEL_DIR) / onnx_model_path.with_suffix('.xml')\n",
    "ir_model_bin = Path(MODEL_DIR) / onnx_model_path.with_suffix('.bin')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, convert this model into the OpenVINO IR using Model Optimizer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/marvin/workspace/greennet/vit/model/vit-base-beans.xml\n",
      "[ SUCCESS ] BIN file: /home/marvin/workspace/greennet/vit/model/vit-base-beans.bin\n"
     ]
    }
   ],
   "source": [
    "!mo -m $onnx_model_path  --output_dir $MODEL_DIR\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compress the model with the following command:\n",
    "\n",
    "`pot -q default -m <path_to_xml> -w <path_to_bin> --engine simplified --data-source <path_to_data>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/openvino/offline_transformations/__init__.py:10: FutureWarning: The module is private and following namespace `offline_transformations` will be removed in the future, use `openvino.runtime.passes` instead!\n",
      "  warnings.warn(\n",
      "INFO:openvino.tools.pot.app.run:Output log dir: compressed\n",
      "INFO:openvino.tools.pot.app.run:Creating pipeline:\n",
      " Algorithm: DefaultQuantization\n",
      " Parameters:\n",
      "\tpreset                     : performance\n",
      "\tstat_subset_size           : 300\n",
      "\ttarget_device              : ANY\n",
      "\tmodel_type                 : None\n",
      "\tdump_intermediate_model    : False\n",
      "\tinplace_statistics         : True\n",
      "\texec_log_dir               : compressed\n",
      " ===========================================================================\n",
      "INFO:openvino.tools.pot.data_loaders.image_loader:Layout value is set [N,C,H,W]\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Inference Engine version:                2022.3.0-9052-9752fafe8eb-releases/2022/3\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Model Optimizer version:                 2022.3.0-9052-9752fafe8eb-releases/2022/3\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Post-Training Optimization Tool version: 2022.3.0-9052-9752fafe8eb-releases/2022/3\n",
      "INFO:openvino.tools.pot.statistics.collector:Start computing statistics for algorithms : DefaultQuantization\n",
      "INFO:openvino.tools.pot.statistics.collector:Computing statistics finished\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Start algorithm: DefaultQuantization\n",
      "INFO:openvino.tools.pot.algorithms.quantization.default.algorithm:Start computing statistics for algorithm : ActivationChannelAlignment\n",
      "INFO:openvino.tools.pot.algorithms.quantization.default.algorithm:Computing statistics finished\n",
      "INFO:openvino.tools.pot.algorithms.quantization.default.algorithm:Start computing statistics for algorithms : MinMaxQuantization,FastBiasCorrection\n",
      "INFO:openvino.tools.pot.algorithms.quantization.default.algorithm:Computing statistics finished\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Finished: DefaultQuantization\n",
      " ===========================================================================\n"
     ]
    }
   ],
   "source": [
    "!pot -q default -m $ir_model_xml -w $ir_model_bin --engine simplified --data-source $CALIB_DIR --output-dir compressed --direct-dump --name $MODEL_NAME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the performance (latency) of quantized model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_model_path = Path('compressed/optimized')\n",
    "optimized_model_xml = optimized_model_path / '{}.xml'.format(MODEL_NAME)\n",
    "optimized_model_bin = optimized_model_path / '{}.bin'.format(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark with models:\n",
      "fp32_model: P95 latency (ms) - 16.08027223846875; Average latency (ms) - 15.07 +\\- 1.23;\n",
      "bf16_model: P95 latency (ms) - 8.533450739923865; Average latency (ms) - 7.91 +\\- 1.04;\n",
      "int8_model: P95 latency (ms) - 9.595101361628622; Average latency (ms) - 8.52 +\\- 0.91;\n",
      "Improvement through bf16 quantization: 1.88x\n",
      "Improvement through int8 quantization: 1.68x\n"
     ]
    }
   ],
   "source": [
    "int8_model = core.compile_model(str(optimized_model_xml))\n",
    "\n",
    "print(f\"benchmark with models:\")\n",
    "rtn_fp32_model = measure_latency(fp32_model, input_tensor)\n",
    "rtn_bf16_model = measure_latency(bf16_model, input_tensor)\n",
    "rtn_int8_model = measure_latency(int8_model, input_tensor)\n",
    "\n",
    "print(f\"fp32_model: {rtn_fp32_model[0]}\")\n",
    "print(f\"bf16_model: {rtn_bf16_model[0]}\")\n",
    "print(f\"int8_model: {rtn_int8_model[0]}\")\n",
    "print(f\"Improvement through bf16 quantization: {round(rtn_fp32_model[1]/rtn_bf16_model[1], 2)}x\")\n",
    "print(f\"Improvement through int8 quantization: {round(rtn_fp32_model[1]/rtn_int8_model[1], 2)}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2022.3.0-9052-9752fafe8eb-releases/2022/3\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2022.3.0-9052-9752fafe8eb-releases/2022/3\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[ WARNING ] Performance hint was not explicitly specified in command line. Device(CPU) performance hint will be set to THROUGHPUT.\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 130.23 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input (node: input) : f32 / [...] / [?,3,224,224]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     output (node: output) : f32 / [...] / [?,3]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[ INFO ] Reshaping model: 'input': [1,3,224,224]\n",
      "[ INFO ] Reshape model took 6.33 ms\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input (node: input) : u8 / [N,C,H,W] / [1,3,224,224]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     output (node: output) : f32 / [...] / [1,3]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 1138.88 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: torch_jit\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 96\n",
      "[ INFO ]   NUM_STREAMS: 96\n",
      "[ INFO ]   AFFINITY: Affinity.CORE\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 96\n",
      "[ INFO ]   PERF_COUNT: False\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'bfloat16'>\n",
      "[ INFO ]   PERFORMANCE_HINT: PerformanceMode.THROUGHPUT\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'input'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'input' with random values \n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 96 inference requests, limits: 60000 ms duration)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 68.00 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Count:            60864 iterations\n",
      "[ INFO ] Duration:         60107.51 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        93.60 ms\n",
      "[ INFO ]    Average:       94.36 ms\n",
      "[ INFO ]    Min:           75.45 ms\n",
      "[ INFO ]    Max:           243.43 ms\n",
      "[ INFO ] Throughput:   1012.59 FPS\n"
     ]
    }
   ],
   "source": [
    "# Inference FP32 model (OpenVINO IR)\n",
    "!benchmark_app -m $ir_model_xml -d CPU -api async -b 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2022.3.0-9052-9752fafe8eb-releases/2022/3\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2022.3.0-9052-9752fafe8eb-releases/2022/3\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[ WARNING ] Performance hint was not explicitly specified in command line. Device(CPU) performance hint will be set to THROUGHPUT.\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 74.60 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input (node: input) : f32 / [...] / [?,3,224,224]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     output (node: output) : f32 / [...] / [?,3]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[ INFO ] Reshaping model: 'input': [1,3,224,224]\n",
      "[ INFO ] Reshape model took 10.80 ms\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input (node: input) : u8 / [N,C,H,W] / [1,3,224,224]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     output (node: output) : f32 / [...] / [1,3]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 2015.19 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: torch_jit\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 96\n",
      "[ INFO ]   NUM_STREAMS: 96\n",
      "[ INFO ]   AFFINITY: Affinity.CORE\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 96\n",
      "[ INFO ]   PERF_COUNT: False\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'bfloat16'>\n",
      "[ INFO ]   PERFORMANCE_HINT: PerformanceMode.THROUGHPUT\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'input'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'input' with random values \n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 96 inference requests, limits: 60000 ms duration)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 46.43 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Count:            89856 iterations\n",
      "[ INFO ] Duration:         60057.77 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        63.52 ms\n",
      "[ INFO ]    Average:       63.93 ms\n",
      "[ INFO ]    Min:           52.74 ms\n",
      "[ INFO ]    Max:           127.33 ms\n",
      "[ INFO ] Throughput:   1496.16 FPS\n"
     ]
    }
   ],
   "source": [
    "!benchmark_app -m $optimized_model_xml -d CPU -api async -b 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the accuraccy of quantized model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp32_accuracy: 96.88%\n",
      "int8_accuracy: 42.19%\n",
      "The quantized model achieves 43.55% accuracy of the fp32 model\n"
     ]
    }
   ],
   "source": [
    "ie = Core()\n",
    "\n",
    "int8_model = ie.compile_model(str(optimized_model_xml))\n",
    "\n",
    "size = len(eval_dataset[\"image\"])\n",
    "\n",
    "fp32_eval_pred = ([predict(fp32_model, eval_dataset[\"image\"][i])[fp32_model.output(0)] for i in range(size)], eval_dataset[\"labels\"])\n",
    "int8_eval_pred = ([predict(int8_model, eval_dataset[\"image\"][i])[int8_model.output(0)] for i in range(size)], eval_dataset[\"labels\"])\n",
    "\n",
    "fp32_accuracy = compute_metrics(fp32_eval_pred)\n",
    "int8_accuracy = compute_metrics(int8_eval_pred)\n",
    "\n",
    "print(f\"fp32_accuracy: {fp32_accuracy['accuracy']*100:.2f}%\")\n",
    "print(f\"int8_accuracy: {int8_accuracy['accuracy']*100:.2f}%\")\n",
    "print(f\"The quantized model achieves {round(int8_accuracy['accuracy']/fp32_accuracy['accuracy'],4)*100:.2f}% accuracy of the fp32 model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
