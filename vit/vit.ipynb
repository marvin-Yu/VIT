{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## OverView\n",
    "In this guide, we show how to enable PyTorch model with OpenVINO, and how to optimize Vision Transformers models with quantize."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setup Development Environment\n",
    "2. Convert the PyTorch model to ONNX model\n",
    "3. Apply Bf16 quantization using OpenVINO\n",
    "3. Apply Int8 quantization using OpenVINO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Development Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 1)) (1.13.0)\n",
      "Requirement already satisfied: transformers in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 2)) (4.26.1)\n",
      "Requirement already satisfied: datasets in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 3)) (2.9.0)\n",
      "Requirement already satisfied: Pillow in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 4)) (9.4.0)\n",
      "Requirement already satisfied: numpy in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 5)) (1.23.4)\n",
      "Requirement already satisfied: intel-extension-for-pytorch==1.13.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 7)) (1.13.0)\n",
      "Requirement already satisfied: onnxruntime in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 8)) (1.14.0)\n",
      "Requirement already satisfied: openvino-dev[ONNX,pytorch]==2022.3.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 9)) (2022.3.0)\n",
      "Requirement already satisfied: torch_tb_profiler in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 10)) (0.4.1)\n",
      "Requirement already satisfied: matplotlib in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from -r ../requirements.txt (line 11)) (3.7.1)\n",
      "Requirement already satisfied: psutil in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from intel-extension-for-pytorch==1.13.0->-r ../requirements.txt (line 7)) (5.9.4)\n",
      "Requirement already satisfied: jstyleson>=0.0.2 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (0.0.2)\n",
      "Requirement already satisfied: openvino-telemetry>=2022.1.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (2022.3.0)\n",
      "Requirement already satisfied: openvino==2022.3.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (2022.3.0)\n",
      "Requirement already satisfied: pandas~=1.3.5 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.25.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (2.28.2)\n",
      "Requirement already satisfied: texttable>=1.6.3 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (1.6.7)\n",
      "Requirement already satisfied: tqdm>=4.54.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (6.0)\n",
      "Requirement already satisfied: scipy>=1.8 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (1.8.1)\n",
      "Requirement already satisfied: opencv-python>=4.5 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (4.7.0.68)\n",
      "Requirement already satisfied: networkx<=2.8.8 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (2.8.8)\n",
      "Requirement already satisfied: addict>=2.4.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (2.4.0)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (0.7.1)\n",
      "Requirement already satisfied: fastjsonschema~=2.15.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (2.15.3)\n",
      "Requirement already satisfied: onnx<=1.12,>=1.8.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (1.12.0)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.18.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (3.19.6)\n",
      "Requirement already satisfied: torchvision<=0.14.0,>=0.9.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (0.14.0)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (0.1.8)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from torch->-r ../requirements.txt (line 1)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from torch->-r ../requirements.txt (line 1)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from torch->-r ../requirements.txt (line 1)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from torch->-r ../requirements.txt (line 1)) (8.5.0.96)\n",
      "Requirement already satisfied: typing-extensions in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from torch->-r ../requirements.txt (line 1)) (4.4.0)\n",
      "Requirement already satisfied: setuptools in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r ../requirements.txt (line 1)) (65.5.0)\n",
      "Requirement already satisfied: wheel in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r ../requirements.txt (line 1)) (0.37.1)\n",
      "Requirement already satisfied: filelock in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 2)) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 2)) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 2)) (2022.10.31)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 2)) (0.13.2)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 3)) (11.0.0)\n",
      "Requirement already satisfied: multiprocess in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 3)) (0.70.14)\n",
      "Requirement already satisfied: dill<0.3.7 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 3)) (0.3.6)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 3)) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 3)) (3.8.4)\n",
      "Requirement already satisfied: responses<0.19 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 3)) (0.18.0)\n",
      "Requirement already satisfied: xxhash in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: sympy in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from onnxruntime->-r ../requirements.txt (line 8)) (1.11.1)\n",
      "Requirement already satisfied: flatbuffers in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from onnxruntime->-r ../requirements.txt (line 8)) (23.1.21)\n",
      "Requirement already satisfied: coloredlogs in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from onnxruntime->-r ../requirements.txt (line 8)) (15.0.1)\n",
      "Requirement already satisfied: tensorboard!=2.1.0,>=1.15 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from torch_tb_profiler->-r ../requirements.txt (line 10)) (2.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 11)) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 11)) (1.0.7)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 11)) (5.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 11)) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 11)) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 11)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 11)) (2.8.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 3)) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 3)) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 3)) (2.1.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 3)) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 3)) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 3)) (22.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->-r ../requirements.txt (line 11)) (3.14.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from pandas~=1.3.5->openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->-r ../requirements.txt (line 11)) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from requests>=2.25.1->openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from requests>=2.25.1->openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from requests>=2.25.1->openvino-dev[ONNX,pytorch]==2022.3.0->-r ../requirements.txt (line 9)) (2022.12.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (2.1.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (1.42.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (1.4.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (2.16.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (1.8.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from coloredlogs->onnxruntime->-r ../requirements.txt (line 8)) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from sympy->onnxruntime->-r ../requirements.txt (line 8)) (1.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (6.0.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.1.0,>=1.15->torch_tb_profiler->-r ../requirements.txt (line 10)) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Pytorch model to ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/transformers/models/vit/modeling_vit.py:165: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if num_channels != self.num_channels:\n",
      "/home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/transformers/models/vit/modeling_vit.py:170: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if height != self.image_size[0] or width != self.image_size[1]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert success!\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "url = 'https://datasets-server.huggingface.co/assets/beans/--/default/validation/30/image/image.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "model_id=\"nateraw/vit-base-beans\"\n",
    "model_name=\"vit-base-beans\"\n",
    "onnx_path = Path(\"onnx\")\n",
    "\n",
    "image_processor = ViTImageProcessor.from_pretrained(model_id)\n",
    "model = ViTForImageClassification.from_pretrained(model_id)\n",
    "\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# print(model(**inputs))\n",
    "\n",
    "torch.onnx.export(model, inputs[\"pixel_values\"], model_name+'.onnx',\n",
    "    input_names=[\"input\"], output_names=[\"output\"],\n",
    "    dynamic_axes={'input': {0:'batch'}, 'output': {0:'batch'}})\n",
    "\n",
    "print(\"Convert success!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Bf16 quantization using OpenVINO\n",
    "\n",
    "### Test the performance (latency) of quantized model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark with models:\n",
      "fp32_model: P95 latency (ms) - 16.660605580545962; Average latency (ms) - 15.12 +\\- 1.59;\n",
      "bf16_model: P95 latency (ms) - 8.549499016953632; Average latency (ms) - 8.00 +\\- 1.64;\n",
      "Improvement through quantization: 1.95x\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import openvino.runtime as ov\n",
    "from time import perf_counter\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from datasets import load_dataset\n",
    "\n",
    "payload=\"https://datasets-server.huggingface.co/assets/beans/--/default/validation/30/image/image.jpg\"\n",
    "image = Image.open(requests.get(payload, stream=True).raw)\n",
    "\n",
    "def measure_latency(model, inputs):\n",
    "    # prepare date\n",
    "    latencies = []\n",
    "    # warm up\n",
    "    for _ in range(10):\n",
    "        _ = model(inputs)\n",
    "    # Timed run\n",
    "    for _ in range(1000):\n",
    "        start_time = perf_counter()\n",
    "        _ = model(inputs)\n",
    "        latency = perf_counter() - start_time\n",
    "        latencies.append(latency)\n",
    "    # Compute run statistics\n",
    "    time_avg_ms = 1000 * np.mean(latencies)\n",
    "    time_std_ms = 1000 * np.std(latencies)\n",
    "    time_p95_ms = 1000 * np.percentile(latencies,95)\n",
    "    return f\"P95 latency (ms) - {time_p95_ms}; Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f};\", time_p95_ms\n",
    "\n",
    "core = ov.Core()\n",
    "core.set_property(\"CPU\", {\"INFERENCE_PRECISION_HINT\": \"f32\"})\n",
    "fp32_model = core.compile_model(model_name+'.onnx', \"AUTO\")\n",
    "\n",
    "core.set_property(\"CPU\", {\"INFERENCE_PRECISION_HINT\": \"bf16\"})\n",
    "bf16_model = core.compile_model(model_name+'.onnx', \"AUTO\")\n",
    "\n",
    "inputs = image_processor(image, return_tensors=\"pt\")\n",
    "# Create tensor from external memory\n",
    "ov_inputs=inputs[\"pixel_values\"].numpy()\n",
    "input_tensor = ov.Tensor(array=ov_inputs, shape=[1, 3, 224, 224])\n",
    "\n",
    "print(f\"benchmark with models:\")\n",
    "rtn_fp32_model = measure_latency(fp32_model, input_tensor)\n",
    "rtn_bf16_model = measure_latency(bf16_model, input_tensor)\n",
    "\n",
    "print(f\"fp32_model: {rtn_fp32_model[0]}\")\n",
    "print(f\"bf16_model: {rtn_bf16_model[0]}\")\n",
    "print(f\"Improvement through quantization: {round(rtn_fp32_model[1]/rtn_bf16_model[1], 2)}x\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the accuraccy of quantized model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset beans (/home/marvin/.cache/huggingface/datasets/beans/default/0.0.0/90c755fb6db1c0ccdad02e897a37969dbf070bed3755d4391e269ff70642d791)\n",
      "100%|██████████| 1/1 [00:00<00:00, 725.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp32_accuracy: 96.88%\n",
      "bf16_accuracy: 96.88%\n",
      "The quantized model achieves 100.00% accuracy of the fp32 model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "eval_dataset = load_dataset(\"beans\",split=[\"test\"])[0]\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    return dict(accuracy=accuracy_score(predictions, labels))\n",
    "\n",
    "def predict(model, image):\n",
    "    inputs = image_processor(image, return_tensors=\"pt\")\n",
    "    ov_inputs=inputs[\"pixel_values\"].numpy()\n",
    "    input_tensor = ov.Tensor(array=ov_inputs, shape=[1, 3, 224, 224])\n",
    "    return model(input_tensor)\n",
    "\n",
    "size = len(eval_dataset[\"image\"])\n",
    "\n",
    "fp32_eval_pred = ([predict(fp32_model, eval_dataset[\"image\"][i])[fp32_model.output(0)] for i in range(size)], eval_dataset[\"labels\"])\n",
    "bf16_eval_pred = ([predict(bf16_model, eval_dataset[\"image\"][i])[bf16_model.output(0)] for i in range(size)], eval_dataset[\"labels\"])\n",
    "\n",
    "fp32_accuracy = compute_metrics(fp32_eval_pred)\n",
    "bf16_accuracy = compute_metrics(bf16_eval_pred)\n",
    "\n",
    "print(f\"fp32_accuracy: {fp32_accuracy['accuracy']*100:.2f}%\")\n",
    "print(f\"bf16_accuracy: {bf16_accuracy['accuracy']*100:.2f}%\")\n",
    "print(f\"The quantized model achieves {round(bf16_accuracy['accuracy']/fp32_accuracy['accuracy'],4)*100:.2f}% accuracy of the fp32 model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Int8 quantization using OpenVINO\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the calibration dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from openvino.runtime import Core, Tensor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set the data and model directories\n",
    "MODEL_DIR = 'model'\n",
    "CALIB_DIR = 'calib'\n",
    "CIFAR_DIR = 'data/datasets/beans'\n",
    "CALIB_SET_SIZE = 300\n",
    "MODEL_NAME = 'vit-base-beans'\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(CALIB_DIR, exist_ok=True)\n",
    "os.makedirs(CIFAR_DIR, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downlaod the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset beans (/home/marvin/.cache/huggingface/datasets/beans/default/0.0.0/90c755fb6db1c0ccdad02e897a37969dbf070bed3755d4391e269ff70642d791)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1218.92it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset('beans')['train']\n",
    "lbs = ds['labels']\n",
    "\n",
    "_index = 0\n",
    "_label_index = [100, 100, 100]\n",
    "\n",
    "for idx, info in enumerate(ds):\n",
    "    im = info[\"image\"]\n",
    "    label = info[\"labels\"]\n",
    "    if _label_index[label] > 0:\n",
    "        im = im.resize((224, 224))\n",
    "        im.save(Path(CALIB_DIR) / f'{label}_{_index}.jpg')\n",
    "        _label_index[label] = _label_index[label] - 1\n",
    "        _index = _index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_path = Path(\".\") / 'vit-base-beans.onnx'\n",
    "ir_model_xml = Path(MODEL_DIR) / onnx_model_path.with_suffix('.xml')\n",
    "ir_model_bin = Path(MODEL_DIR) / onnx_model_path.with_suffix('.bin')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, convert this model into the OpenVINO IR using Model Optimizer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/marvin/workspace/greennet/vit/model/vit-base-beans.xml\n",
      "[ SUCCESS ] BIN file: /home/marvin/workspace/greennet/vit/model/vit-base-beans.bin\n"
     ]
    }
   ],
   "source": [
    "!mo -m $onnx_model_path  --output_dir $MODEL_DIR\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compress the model with the following command:\n",
    "\n",
    "`pot -q default -m <path_to_xml> -w <path_to_bin> --engine simplified --data-source <path_to_data>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/openvino/offline_transformations/__init__.py:10: FutureWarning: The module is private and following namespace `offline_transformations` will be removed in the future, use `openvino.runtime.passes` instead!\n",
      "  warnings.warn(\n",
      "INFO:openvino.tools.pot.app.run:Output log dir: compressed\n",
      "INFO:openvino.tools.pot.app.run:Creating pipeline:\n",
      " Algorithm: DefaultQuantization\n",
      " Parameters:\n",
      "\tpreset                     : performance\n",
      "\tstat_subset_size           : 300\n",
      "\ttarget_device              : ANY\n",
      "\tmodel_type                 : None\n",
      "\tdump_intermediate_model    : False\n",
      "\tinplace_statistics         : True\n",
      "\texec_log_dir               : compressed\n",
      " ===========================================================================\n",
      "INFO:openvino.tools.pot.data_loaders.image_loader:Layout value is set [N,C,H,W]\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Inference Engine version:                2022.3.0-9052-9752fafe8eb-releases/2022/3\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Model Optimizer version:                 2022.3.0-9052-9752fafe8eb-releases/2022/3\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Post-Training Optimization Tool version: 2022.3.0-9052-9752fafe8eb-releases/2022/3\n",
      "INFO:openvino.tools.pot.statistics.collector:Start computing statistics for algorithms : DefaultQuantization\n",
      "INFO:openvino.tools.pot.statistics.collector:Computing statistics finished\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Start algorithm: DefaultQuantization\n",
      "INFO:openvino.tools.pot.algorithms.quantization.default.algorithm:Start computing statistics for algorithm : ActivationChannelAlignment\n",
      "INFO:openvino.tools.pot.algorithms.quantization.default.algorithm:Computing statistics finished\n",
      "INFO:openvino.tools.pot.algorithms.quantization.default.algorithm:Start computing statistics for algorithms : MinMaxQuantization,FastBiasCorrection\n",
      "INFO:openvino.tools.pot.algorithms.quantization.default.algorithm:Computing statistics finished\n",
      "INFO:openvino.tools.pot.pipeline.pipeline:Finished: DefaultQuantization\n",
      " ===========================================================================\n"
     ]
    }
   ],
   "source": [
    "!pot -q default -m $ir_model_xml -w $ir_model_bin --engine simplified --data-source $CALIB_DIR --output-dir compressed --direct-dump --name $MODEL_NAME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the performance (latency) of quantized model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_model_path = Path('compressed/optimized')\n",
    "optimized_model_xml = optimized_model_path / '{}.xml'.format(MODEL_NAME)\n",
    "optimized_model_bin = optimized_model_path / '{}.bin'.format(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark with models:\n",
      "fp32_model: P95 latency (ms) - 16.08027223846875; Average latency (ms) - 15.07 +\\- 1.23;\n",
      "bf16_model: P95 latency (ms) - 8.533450739923865; Average latency (ms) - 7.91 +\\- 1.04;\n",
      "int8_model: P95 latency (ms) - 9.595101361628622; Average latency (ms) - 8.52 +\\- 0.91;\n",
      "Improvement through bf16 quantization: 1.88x\n",
      "Improvement through int8 quantization: 1.68x\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "int8_model = core.compile_model(str(optimized_model_xml))\n",
    "\n",
    "print(f\"benchmark with models:\")\n",
    "rtn_fp32_model = measure_latency(fp32_model, input_tensor)\n",
    "rtn_bf16_model = measure_latency(bf16_model, input_tensor)\n",
    "rtn_int8_model = measure_latency(int8_model, input_tensor)\n",
    "\n",
    "print(f\"fp32_model: {rtn_fp32_model[0]}\")\n",
    "print(f\"bf16_model: {rtn_bf16_model[0]}\")\n",
    "print(f\"int8_model: {rtn_int8_model[0]}\")\n",
    "print(f\"Improvement through bf16 quantization: {round(rtn_fp32_model[1]/rtn_bf16_model[1], 2)}x\")\n",
    "print(f\"Improvement through int8 quantization: {round(rtn_fp32_model[1]/rtn_int8_model[1], 2)}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2022.3.0-9052-9752fafe8eb-releases/2022/3\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2022.3.0-9052-9752fafe8eb-releases/2022/3\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[ WARNING ] Performance hint was not explicitly specified in command line. Device(CPU) performance hint will be set to THROUGHPUT.\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 130.23 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input (node: input) : f32 / [...] / [?,3,224,224]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     output (node: output) : f32 / [...] / [?,3]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[ INFO ] Reshaping model: 'input': [1,3,224,224]\n",
      "[ INFO ] Reshape model took 6.33 ms\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input (node: input) : u8 / [N,C,H,W] / [1,3,224,224]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     output (node: output) : f32 / [...] / [1,3]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 1138.88 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: torch_jit\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 96\n",
      "[ INFO ]   NUM_STREAMS: 96\n",
      "[ INFO ]   AFFINITY: Affinity.CORE\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 96\n",
      "[ INFO ]   PERF_COUNT: False\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'bfloat16'>\n",
      "[ INFO ]   PERFORMANCE_HINT: PerformanceMode.THROUGHPUT\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'input'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'input' with random values \n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 96 inference requests, limits: 60000 ms duration)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 68.00 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Count:            60864 iterations\n",
      "[ INFO ] Duration:         60107.51 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        93.60 ms\n",
      "[ INFO ]    Average:       94.36 ms\n",
      "[ INFO ]    Min:           75.45 ms\n",
      "[ INFO ]    Max:           243.43 ms\n",
      "[ INFO ] Throughput:   1012.59 FPS\n"
     ]
    }
   ],
   "source": [
    "# Inference FP32 model (OpenVINO IR)\n",
    "!benchmark_app -m $ir_model_xml -d CPU -api async -b 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2022.3.0-9052-9752fafe8eb-releases/2022/3\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2022.3.0-9052-9752fafe8eb-releases/2022/3\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[ WARNING ] Performance hint was not explicitly specified in command line. Device(CPU) performance hint will be set to THROUGHPUT.\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 74.60 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input (node: input) : f32 / [...] / [?,3,224,224]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     output (node: output) : f32 / [...] / [?,3]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[ INFO ] Reshaping model: 'input': [1,3,224,224]\n",
      "[ INFO ] Reshape model took 10.80 ms\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input (node: input) : u8 / [N,C,H,W] / [1,3,224,224]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     output (node: output) : f32 / [...] / [1,3]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 2015.19 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: torch_jit\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 96\n",
      "[ INFO ]   NUM_STREAMS: 96\n",
      "[ INFO ]   AFFINITY: Affinity.CORE\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 96\n",
      "[ INFO ]   PERF_COUNT: False\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'bfloat16'>\n",
      "[ INFO ]   PERFORMANCE_HINT: PerformanceMode.THROUGHPUT\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'input'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'input' with random values \n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 96 inference requests, limits: 60000 ms duration)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 46.43 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Count:            89856 iterations\n",
      "[ INFO ] Duration:         60057.77 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        63.52 ms\n",
      "[ INFO ]    Average:       63.93 ms\n",
      "[ INFO ]    Min:           52.74 ms\n",
      "[ INFO ]    Max:           127.33 ms\n",
      "[ INFO ] Throughput:   1496.16 FPS\n"
     ]
    }
   ],
   "source": [
    "!benchmark_app -m $optimized_model_xml -d CPU -api async -b 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the accuraccy of quantized model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp32_accuracy: 96.88%\n",
      "int8_accuracy: 42.19%\n",
      "The quantized model achieves 43.55% accuracy of the fp32 model\n"
     ]
    }
   ],
   "source": [
    "ie = Core()\n",
    "\n",
    "int8_model = ie.compile_model(str(optimized_model_xml))\n",
    "\n",
    "size = len(eval_dataset[\"image\"])\n",
    "\n",
    "fp32_eval_pred = ([predict(fp32_model, eval_dataset[\"image\"][i])[fp32_model.output(0)] for i in range(size)], eval_dataset[\"labels\"])\n",
    "int8_eval_pred = ([predict(int8_model, eval_dataset[\"image\"][i])[int8_model.output(0)] for i in range(size)], eval_dataset[\"labels\"])\n",
    "\n",
    "fp32_accuracy = compute_metrics(fp32_eval_pred)\n",
    "int8_accuracy = compute_metrics(int8_eval_pred)\n",
    "\n",
    "print(f\"fp32_accuracy: {fp32_accuracy['accuracy']*100:.2f}%\")\n",
    "print(f\"int8_accuracy: {int8_accuracy['accuracy']*100:.2f}%\")\n",
    "print(f\"The quantized model achieves {round(int8_accuracy['accuracy']/fp32_accuracy['accuracy'],4)*100:.2f}% accuracy of the fp32 model\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Encoder fusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fp32 encoder fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/workspace/greennet/vit/extension ~/workspace/greennet/vit\n",
      "--2023-03-22 02:09:52--  https://github.com/oneapi-src/oneDNN/releases/download/v0.21-rc/mklml_lnx_2019.0.5.20190502.tgz\n",
      "Resolving child-prc.intel.com (child-prc.intel.com)... 10.239.120.55\n",
      "Connecting to child-prc.intel.com (child-prc.intel.com)|10.239.120.55|:913... connected.\n",
      "Proxy request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/58414589/8c825300-d8a7-11e9-918a-f6d6bce48f33?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230322%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230322T060920Z&X-Amz-Expires=300&X-Amz-Signature=95f948ebf76544dd9338759fcc8e03d77b7fafbc1db183bdf4cc855e4deb7a13&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=58414589&response-content-disposition=attachment%3B%20filename%3Dmklml_lnx_2019.0.5.20190502.tgz&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-03-22 02:09:53--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/58414589/8c825300-d8a7-11e9-918a-f6d6bce48f33?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230322%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230322T060920Z&X-Amz-Expires=300&X-Amz-Signature=95f948ebf76544dd9338759fcc8e03d77b7fafbc1db183bdf4cc855e4deb7a13&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=58414589&response-content-disposition=attachment%3B%20filename%3Dmklml_lnx_2019.0.5.20190502.tgz&response-content-type=application%2Foctet-stream\n",
      "Connecting to child-prc.intel.com (child-prc.intel.com)|10.239.120.55|:913... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 69728113 (66M) [application/octet-stream]\n",
      "Saving to: ‘mklml_lnx_2019.0.5.20190502.tgz’\n",
      "\n",
      "mklml_lnx_2019.0.5. 100%[===================>]  66.50M  13.3MB/s    in 6.2s    \n",
      "\n",
      "2023-03-22 02:10:00 (10.7 MB/s) - ‘mklml_lnx_2019.0.5.20190502.tgz’ saved [69728113/69728113]\n",
      "\n",
      "~/workspace/greennet/vit\n"
     ]
    }
   ],
   "source": [
    "# prepare env\n",
    "!pushd extension && bash prepare.sh && popd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/workspace/greennet/vit/extension ~/workspace/greennet/vit\n",
      "running install\n",
      "/home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing fused_bert.egg-info/PKG-INFO\n",
      "writing dependency_links to fused_bert.egg-info/dependency_links.txt\n",
      "writing top-level names to fused_bert.egg-info/top_level.txt\n",
      "reading manifest file 'fused_bert.egg-info/SOURCES.txt'\n",
      "writing manifest file 'fused_bert.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_ext\n",
      "building 'fused_bert' extension\n",
      "Emitting ninja build file /home/marvin/workspace/greennet/vit/extension/build/temp.linux-x86_64-cpython-39/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/1] c++ -MMD -MF /home/marvin/workspace/greennet/vit/extension/build/temp.linux-x86_64-cpython-39/bert.o.d -pthread -B /home/marvin/.conda/envs/ipex/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/marvin/.conda/envs/ipex/include -I/home/marvin/.conda/envs/ipex/include -fPIC -O2 -isystem /home/marvin/.conda/envs/ipex/include -fPIC -DUSE_ONEDNN=1 -I/home/marvin/workspace/greennet/vit/extension/mklml/include -I/home/marvin/workspace/greennet/vit/extension/onednn_helper -I/home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/torch/include -I/home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/torch/include/TH -I/home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/torch/include/THC -I/home/marvin/.conda/envs/ipex/include/python3.9 -c -c /home/marvin/workspace/greennet/vit/extension/bert.cpp -o /home/marvin/workspace/greennet/vit/extension/build/temp.linux-x86_64-cpython-39/bert.o -fopenmp -mavx512f -mavx512bw -mavx512vl -mfma -std=c++17 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_bert -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "In file included from /home/marvin/workspace/greennet/vit/extension/bert.cpp:9:\n",
      "/home/marvin/workspace/greennet/vit/extension/bert_layer_int8.h: In member function ‘void Int8BertLayer::denseWithSum(hpj::Matrix<unsigned char>&, hpj::Matrix<signed char>&, hpj::Vector<float>&, hpj::Vector<float>&, hpj::Matrix<float>&, hpj::Matrix<float>&)’:\n",
      "/home/marvin/workspace/greennet/vit/extension/bert_layer_int8.h:514:15: warning: unused variable ‘rmax’ [-Wunused-variable]\n",
      "         float rmax = 0, rmin = 0;\n",
      "               ^~~~\n",
      "/home/marvin/workspace/greennet/vit/extension/bert_layer_int8.h:514:25: warning: unused variable ‘rmin’ [-Wunused-variable]\n",
      "         float rmax = 0, rmin = 0;\n",
      "                         ^~~~\n",
      "/home/marvin/workspace/greennet/vit/extension/bert_layer_int8.h: In member function ‘void Int8BertLayer::computeSoftmax()’:\n",
      "/home/marvin/workspace/greennet/vit/extension/bert_layer_int8.h:1147:27: warning: unused variable ‘tail_mask’ [-Wunused-variable]\n",
      "                 __mmask16 tail_mask = (ctx->tokenSize % 16 == 0 ? 0xffff : (1 << (ctx->tokenSize % 16)) - 1);\n",
      "                           ^~~~~~~~~\n",
      "/home/marvin/workspace/greennet/vit/extension/bert.cpp: In destructor ‘BertEncoder::~BertEncoder()’:\n",
      "/home/marvin/workspace/greennet/vit/extension/bert.cpp:37:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<BatchBertLayer*>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
      "     for (int i = 0; i < fp32_bert_layers.size(); ++i) {\n",
      "                     ~~^~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "/home/marvin/workspace/greennet/vit/extension/bert.cpp:40:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<Int8BertLayer*>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
      "     for (int i = 0; i < int8_bert_layers.size(); ++i) {\n",
      "                     ~~^~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "g++ -pthread -B /home/marvin/.conda/envs/ipex/compiler_compat -shared -Wl,-rpath,/home/marvin/.conda/envs/ipex/lib -Wl,-rpath-link,/home/marvin/.conda/envs/ipex/lib -L/home/marvin/.conda/envs/ipex/lib -L/home/marvin/.conda/envs/ipex/lib -Wl,-rpath,/home/marvin/.conda/envs/ipex/lib -Wl,-rpath-link,/home/marvin/.conda/envs/ipex/lib -L/home/marvin/.conda/envs/ipex/lib /home/marvin/workspace/greennet/vit/extension/build/temp.linux-x86_64-cpython-39/bert.o -L/home/marvin/workspace/greennet/vit/extension/mklml/lib -L/home/marvin/workspace/greennet/vit/extension -L/home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/torch/lib -Wl,--enable-new-dtags,-R/home/marvin/workspace/greennet/vit/extension/mklml/lib -Wl,--enable-new-dtags,-R/home/marvin/workspace/greennet/vit/extension -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-39/fused_bert.cpython-39-x86_64-linux-gnu.so -l:libsgemm.a -l:libigemm.a -liomp5 -lmklml_intel -ldnnl\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-cpython-39/fused_bert.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "creating stub loader for fused_bert.cpython-39-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fused_bert.py to fused_bert.cpython-39.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying fused_bert.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying fused_bert.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying fused_bert.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying fused_bert.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "__pycache__.fused_bert.cpython-39: module references __file__\n",
      "creating 'dist/fused_bert-0.1-py3.9-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing fused_bert-0.1-py3.9-linux-x86_64.egg\n",
      "removing '/home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/fused_bert-0.1-py3.9-linux-x86_64.egg' (and everything under it)\n",
      "creating /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/fused_bert-0.1-py3.9-linux-x86_64.egg\n",
      "Extracting fused_bert-0.1-py3.9-linux-x86_64.egg to /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages\n",
      "fused-bert 0.1 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /home/marvin/.conda/envs/ipex/lib/python3.9/site-packages/fused_bert-0.1-py3.9-linux-x86_64.egg\n",
      "Processing dependencies for fused-bert==0.1\n",
      "Finished processing dependencies for fused-bert==0.1\n",
      "~/workspace/greennet/vit\n"
     ]
    }
   ],
   "source": [
    "# install custom package\n",
    "!pushd extension && python setup.py install && popd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: cats-image/image\n",
      "Found cached dataset cats-image (/home/marvin/.cache/huggingface/datasets/huggingface___cats-image/image/1.9.0/68fbc793fb10cd165e490867f5d61fa366086ea40c73e549a020103dcb4f597e)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1100.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output with original model: \n",
      " BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 0.1559,  0.0914,  0.1518,  ..., -0.3180, -0.0859, -0.0903],\n",
      "         [-0.2254,  0.0864,  0.4752,  ..., -0.1781,  0.1726,  0.1334],\n",
      "         [ 0.0444,  0.0677,  0.4199,  ..., -0.2576,  0.1191,  0.0130],\n",
      "         ...,\n",
      "         [-0.0153, -0.0396,  0.1684,  ..., -0.1672,  0.1869,  0.1025],\n",
      "         [ 0.0249, -0.0382,  0.2046,  ...,  0.0517,  0.1489,  0.1320],\n",
      "         [-0.1748, -0.0254,  0.2523,  ..., -0.1474,  0.1627,  0.1325]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 5.8399e-02, -3.0683e-01,  3.1213e-01, -1.1009e-01, -1.4752e-01,\n",
      "          4.9735e-01, -1.5786e-01,  4.8658e-01, -4.6255e-01,  2.4344e-01,\n",
      "          2.9942e-02,  2.8738e-01, -4.8914e-01, -9.9510e-03, -2.8943e-01,\n",
      "          3.1443e-01, -6.2883e-02, -2.6637e-01, -3.9652e-01,  2.9896e-01,\n",
      "          2.1507e-01, -1.9265e-01,  1.1786e-01,  2.5995e-01,  3.5440e-01,\n",
      "         -3.7968e-01,  4.8320e-01, -3.5686e-01,  2.3996e-01, -8.0731e-01,\n",
      "          1.1701e-02,  4.9429e-01,  6.9714e-01,  5.2732e-01,  6.8406e-01,\n",
      "          5.4112e-01, -3.6567e-01, -5.8526e-02,  2.2564e-01,  2.7409e-01,\n",
      "          4.5724e-01, -4.2382e-01, -4.7543e-02,  3.8201e-01,  1.1637e-01,\n",
      "         -6.0073e-01, -6.1237e-01, -2.9059e-01, -1.6196e-01, -2.2600e-01,\n",
      "          3.3057e-01, -4.6795e-01, -1.0904e-01, -1.8052e-01, -1.9760e-01,\n",
      "          1.6378e-01,  4.4932e-01,  3.2078e-01, -8.4978e-03,  2.4506e-01,\n",
      "          4.4046e-01, -4.5339e-01, -5.6663e-01, -1.7683e-01, -5.0688e-01,\n",
      "         -3.8825e-01, -6.4027e-02,  4.3136e-01,  3.6378e-01,  3.2494e-01,\n",
      "         -1.0437e-01, -1.0710e-01,  4.1625e-01,  2.8193e-01,  1.8729e-01,\n",
      "          3.0436e-01, -2.7424e-01,  7.8963e-02,  2.0665e-01,  4.0307e-01,\n",
      "          5.6357e-01, -4.3966e-01,  1.1214e-01, -3.3859e-01, -2.4644e-01,\n",
      "          5.0045e-01,  4.5928e-01,  1.7511e-02, -3.1132e-01, -4.3624e-01,\n",
      "          2.4134e-01, -6.9099e-01, -4.0767e-02, -4.1386e-01, -1.0100e-02,\n",
      "         -1.9097e-01, -3.9957e-01,  5.3397e-01, -1.0371e-01, -5.7820e-01,\n",
      "          9.2758e-02,  6.8151e-02, -1.8034e-01, -2.0102e-01,  1.9885e-01,\n",
      "         -1.5536e-01,  4.0060e-01, -8.4662e-02,  6.6026e-01, -1.6513e-01,\n",
      "          6.0235e-01,  2.7247e-01, -3.7356e-01, -6.0968e-01,  4.8872e-01,\n",
      "          5.2307e-01, -1.3361e-01,  2.1791e-01,  2.2186e-01, -4.4632e-01,\n",
      "         -3.0130e-01, -2.5047e-01,  3.7132e-02, -7.2610e-01,  2.1982e-01,\n",
      "          4.1558e-02, -3.3696e-01, -6.2595e-02,  1.2199e-02, -7.0608e-01,\n",
      "          2.0988e-01, -7.9426e-02, -2.2468e-01,  3.1440e-01, -6.6139e-01,\n",
      "         -2.1012e-01,  4.8698e-01, -3.8478e-01,  1.4674e-01, -4.9661e-01,\n",
      "          2.5234e-01,  1.6793e-01,  1.6673e-01, -7.9136e-01, -7.4222e-01,\n",
      "          1.3967e-02, -4.6990e-02,  1.5588e-01, -1.5090e-01,  3.5754e-01,\n",
      "          4.6368e-01, -2.4381e-01, -1.1749e-01, -2.9684e-01,  3.8067e-01,\n",
      "         -1.1229e-01,  2.3759e-02, -5.8056e-02, -5.4476e-02,  1.9663e-01,\n",
      "          4.9049e-02, -6.6287e-01, -3.3389e-01, -6.9687e-01, -9.5334e-02,\n",
      "          1.5625e-01, -6.0157e-01,  1.1714e-01, -5.8221e-01,  1.3791e-01,\n",
      "         -2.3029e-01, -2.2299e-01,  4.3021e-01, -9.5817e-03, -8.5030e-01,\n",
      "         -1.1477e-01, -2.6673e-01,  5.3302e-01,  3.4741e-01, -1.2262e-01,\n",
      "         -1.3222e-02,  3.8602e-01,  1.6366e-03,  4.7331e-01,  1.2913e-01,\n",
      "          1.3584e-01,  6.5476e-01,  3.4261e-01, -3.0964e-01, -4.7250e-01,\n",
      "         -5.0476e-01,  6.8812e-01, -1.0612e-01, -2.9400e-01,  1.1402e-01,\n",
      "          2.5638e-01, -1.6562e-01,  4.0749e-01,  2.7292e-01, -4.1630e-01,\n",
      "          2.1262e-01, -2.5268e-01,  2.7511e-01,  7.8152e-01,  3.2154e-01,\n",
      "          1.2416e-01,  1.5977e-01, -3.3072e-01,  1.3382e-01,  3.7724e-01,\n",
      "          6.4949e-01, -2.8926e-01, -1.9544e-01, -6.3353e-01,  4.5003e-01,\n",
      "         -3.5091e-01, -1.2037e-01,  4.5943e-01, -1.8009e-01, -3.4879e-01,\n",
      "         -1.9784e-01, -5.4147e-01,  4.0277e-01,  4.5194e-01,  2.3656e-01,\n",
      "         -5.6903e-01,  7.6075e-02,  5.4688e-01, -6.6555e-01, -1.7622e-01,\n",
      "         -4.6347e-01,  1.4470e-02, -1.2911e-01, -2.5562e-01, -1.2145e-01,\n",
      "          5.3607e-01, -2.3647e-02,  9.2892e-03, -7.1595e-01, -6.0174e-02,\n",
      "          3.6872e-02,  6.7446e-03,  4.1739e-01,  2.3007e-02,  1.2953e-01,\n",
      "          4.1096e-01, -5.3745e-02,  3.0180e-01,  5.3177e-02, -1.5922e-01,\n",
      "          7.3978e-01,  1.5180e-01,  7.5677e-02, -4.0224e-01,  9.0101e-02,\n",
      "          7.1478e-02,  1.4431e-01, -7.5210e-01, -3.6932e-01,  6.2180e-01,\n",
      "          4.1401e-01, -2.5098e-01,  4.1242e-01,  4.4754e-01, -8.4019e-02,\n",
      "         -6.5461e-01,  2.7639e-01,  1.6619e-01, -2.4061e-01,  1.0564e-01,\n",
      "          5.3407e-01,  6.5955e-01, -6.2184e-01, -3.3967e-01,  9.7421e-02,\n",
      "         -4.7683e-01,  2.8944e-01,  7.1257e-01,  1.5123e-01,  1.6111e-01,\n",
      "         -3.4519e-01,  4.0488e-01,  2.8341e-01,  1.6014e-01,  1.2616e-01,\n",
      "         -6.7210e-01,  9.7288e-02,  3.8720e-01,  6.2359e-01,  2.0742e-01,\n",
      "          2.4551e-01, -2.4559e-01, -4.0337e-01,  3.8191e-01,  7.7679e-02,\n",
      "         -1.2860e-01, -1.0053e-01,  4.2053e-02, -2.2481e-01,  3.6386e-01,\n",
      "          6.6649e-01,  2.0140e-01,  9.2744e-02,  7.1225e-03,  4.3717e-01,\n",
      "         -5.0022e-01, -3.3084e-01,  2.0534e-01,  1.2237e-01,  2.4543e-01,\n",
      "          7.5969e-01,  6.7590e-01,  3.7051e-01, -2.9076e-01,  1.4151e-01,\n",
      "          9.5215e-02,  5.1937e-01,  2.1608e-01,  6.7187e-01,  3.7702e-01,\n",
      "          4.5188e-01, -1.6543e-02, -1.3094e-01, -5.7231e-01,  2.2326e-01,\n",
      "         -1.8231e-01, -2.6103e-01,  2.7394e-01, -1.4468e-01,  3.3944e-01,\n",
      "         -6.9675e-01,  1.3390e-01, -2.1033e-02, -7.6674e-01,  5.7956e-01,\n",
      "          7.2288e-01,  5.7731e-02, -2.9241e-01, -3.1415e-01,  2.4233e-01,\n",
      "         -1.9839e-01,  3.3393e-01,  2.6760e-01,  4.5880e-01, -4.1619e-01,\n",
      "          7.2496e-01,  2.7416e-01,  7.6784e-01,  2.6550e-01, -3.8287e-01,\n",
      "         -7.0116e-02, -1.9747e-02,  3.1078e-01, -2.7025e-02,  1.0560e-01,\n",
      "          3.1172e-01,  1.0529e-02,  1.3119e-01,  7.3345e-02,  6.9890e-02,\n",
      "         -8.2107e-01, -2.2102e-01, -5.0245e-01,  6.5445e-02, -3.8067e-01,\n",
      "         -1.3855e-01,  2.3979e-01, -1.6183e-01,  1.5684e-01, -3.6527e-01,\n",
      "         -5.5528e-02,  4.3381e-01,  1.0850e-01,  3.8653e-01, -3.7031e-01,\n",
      "         -5.8345e-01,  3.6348e-01,  1.7560e-01, -7.7397e-02, -2.7175e-01,\n",
      "          3.3853e-01, -1.5536e-02,  9.2824e-02,  3.0169e-01,  2.0072e-01,\n",
      "          2.3207e-01,  4.0615e-01, -7.9739e-01, -1.8515e-01, -3.9296e-01,\n",
      "         -7.6753e-01,  1.3696e-01,  1.7097e-01,  5.1179e-01,  1.2511e-01,\n",
      "          2.1475e-01, -2.9436e-01,  7.6488e-02, -4.3098e-01, -5.5470e-01,\n",
      "          3.7150e-01, -3.4330e-02,  3.9570e-01,  7.3408e-01, -2.1937e-01,\n",
      "          1.0290e-01, -9.5120e-01, -3.5084e-02,  7.4985e-02,  4.1041e-01,\n",
      "          1.7073e-01, -4.1514e-01,  5.2691e-01, -2.1257e-01,  1.0503e-02,\n",
      "         -7.6262e-02, -3.1197e-01,  6.8580e-01, -2.9188e-01,  1.0809e-01,\n",
      "          2.1453e-01,  5.9494e-01, -3.9562e-01, -6.1215e-03,  6.7966e-01,\n",
      "         -2.8134e-01,  2.2308e-01,  5.5857e-01,  2.2602e-01,  6.6382e-01,\n",
      "          2.4675e-01, -6.1403e-02,  2.9579e-01,  2.9564e-01,  1.2897e-01,\n",
      "          6.5476e-02,  3.6293e-01,  6.5790e-01, -3.3637e-02,  5.4009e-01,\n",
      "          3.2958e-01, -3.7644e-01, -4.6378e-01,  9.2770e-02,  3.6307e-01,\n",
      "          1.1353e-01,  2.5996e-01,  1.7849e-01, -1.5862e-01,  6.4568e-02,\n",
      "          1.4384e-01, -3.1834e-01, -8.2484e-02, -3.2559e-01, -5.1949e-01,\n",
      "          5.7703e-01,  5.5213e-01, -4.9496e-01, -1.4973e-01, -5.8562e-01,\n",
      "          1.4379e-01, -1.6822e-01, -6.1914e-01,  3.8340e-01,  3.2489e-01,\n",
      "          5.6003e-01,  4.3218e-01,  4.4030e-01, -7.1287e-02, -2.8293e-01,\n",
      "          4.7222e-01,  2.8984e-01,  4.8794e-02,  6.3796e-02,  6.3304e-01,\n",
      "         -4.5820e-01,  7.8582e-02, -1.4631e-01,  3.1295e-01,  4.9457e-01,\n",
      "          2.1801e-01, -3.4136e-01,  1.4820e-01, -3.3367e-01,  2.7932e-01,\n",
      "          1.2559e-01, -2.4761e-02, -6.8904e-01,  3.7935e-01,  1.8919e-01,\n",
      "          3.7143e-01, -1.4413e-01, -3.3997e-01, -2.7971e-01,  3.6755e-01,\n",
      "          6.9807e-01, -5.2834e-01,  2.4842e-01,  1.2471e-01,  8.9951e-02,\n",
      "         -1.3570e-01, -1.6457e-02, -3.8017e-01,  6.8796e-01, -4.3004e-02,\n",
      "         -3.8376e-01,  2.4526e-01, -2.0187e-02, -4.4745e-01, -3.7117e-01,\n",
      "          4.2819e-01,  4.3499e-01,  2.8113e-01,  4.9726e-01,  5.7089e-01,\n",
      "         -9.8565e-02, -3.7851e-01, -5.7216e-01,  5.0728e-01, -2.3844e-01,\n",
      "         -8.3904e-01, -6.6675e-01, -6.9328e-01, -4.3677e-01, -7.1418e-01,\n",
      "         -4.9371e-01,  3.2446e-01, -2.6477e-01, -3.6840e-01,  3.9068e-01,\n",
      "          3.3788e-01, -2.1292e-01,  2.2727e-01,  2.1302e-01,  2.7809e-01,\n",
      "         -4.1122e-01, -4.5486e-01, -2.4513e-01,  5.3639e-01, -2.9416e-01,\n",
      "         -1.6414e-02, -4.0171e-01, -1.9265e-01,  4.6666e-02,  2.2634e-01,\n",
      "         -3.3881e-01, -2.4607e-01,  7.6096e-01, -2.0232e-01, -6.3531e-01,\n",
      "          5.4065e-01, -3.9648e-02, -4.7939e-01,  7.1906e-01, -8.5368e-01,\n",
      "          3.9528e-04, -6.0829e-01, -2.2062e-01,  4.4581e-01,  2.7916e-02,\n",
      "         -9.8977e-02, -3.4840e-02,  1.4511e-01,  9.5326e-02, -6.1228e-01,\n",
      "          6.6275e-01, -5.2396e-01,  2.0002e-01, -2.7202e-01,  3.6367e-01,\n",
      "         -4.7337e-01, -1.5994e-01, -6.1996e-01,  2.6273e-01,  7.1448e-01,\n",
      "         -6.7823e-02,  4.1157e-02, -5.0856e-01,  4.8723e-01, -3.9550e-03,\n",
      "          1.7404e-01, -7.4750e-01,  7.1912e-02, -1.8141e-01,  6.0255e-01,\n",
      "         -2.5703e-01, -1.3624e-01, -5.9815e-01,  3.0625e-01,  4.0591e-01,\n",
      "         -6.2150e-04, -3.1610e-01, -5.9029e-01,  6.0556e-01, -2.1644e-01,\n",
      "          5.2475e-02,  3.0874e-01,  2.0803e-01, -5.6677e-01,  4.7860e-01,\n",
      "          8.1961e-02,  7.7025e-01, -5.3661e-01, -2.1032e-01,  2.2392e-01,\n",
      "         -6.1550e-02,  2.7167e-01, -4.8437e-01, -2.7542e-02,  5.8029e-01,\n",
      "          1.1535e-02, -1.2251e-01,  4.8351e-01,  4.1625e-01, -2.3692e-01,\n",
      "         -2.2231e-01,  4.0339e-01,  2.6744e-01,  4.6288e-01,  2.0605e-01,\n",
      "          3.3893e-01, -6.3740e-01, -1.1953e-01, -2.9474e-01, -2.0230e-01,\n",
      "         -6.5302e-01,  6.5237e-01, -3.5228e-01,  3.6646e-01,  1.8212e-01,\n",
      "          3.7832e-03, -7.4805e-01, -9.9035e-01, -3.7043e-01, -3.2308e-01,\n",
      "          1.3876e-02,  1.2306e-01, -3.5638e-01, -4.5204e-01,  1.5339e-01,\n",
      "         -7.5218e-02,  5.1955e-01, -5.5930e-01,  2.8108e-01, -4.6888e-01,\n",
      "         -3.7634e-02, -2.7399e-01, -5.6728e-01,  5.5187e-01, -5.7696e-01,\n",
      "          2.7052e-01,  4.4848e-01, -1.5765e-01,  1.6915e-01, -3.0343e-01,\n",
      "          2.4804e-01,  2.1601e-01, -4.1728e-01, -1.9910e-01,  2.3341e-01,\n",
      "          1.6413e-02,  4.9791e-01,  1.1169e-01,  2.9309e-01, -1.3740e-01,\n",
      "          7.0252e-01, -5.1568e-01, -2.3121e-01, -5.0268e-01,  2.3819e-01,\n",
      "         -5.9981e-02, -6.6980e-01, -1.3046e-01,  4.1493e-02,  2.3869e-01,\n",
      "         -1.1551e-01,  3.9865e-01, -3.8680e-01,  2.2352e-01, -3.4607e-01,\n",
      "         -2.7853e-01,  4.5486e-01, -6.4218e-01, -2.4997e-01,  4.3725e-01,\n",
      "         -1.6785e-01,  3.6944e-01,  6.4575e-01, -9.9729e-02,  4.1417e-01,\n",
      "         -1.4660e-01,  5.8890e-01,  2.2198e-02,  2.4174e-01, -3.9738e-02,\n",
      "         -1.6135e-01, -5.8573e-01,  3.0327e-01,  2.2434e-01,  2.4299e-01,\n",
      "         -5.1917e-01, -2.6197e-01, -1.8781e-01, -6.1012e-01, -1.3243e-02,\n",
      "         -5.6108e-01, -1.1651e-01, -1.8258e-01,  3.5039e-01,  5.1553e-01,\n",
      "         -2.2207e-01,  1.4063e-02,  4.4455e-02,  6.5834e-02,  4.7592e-01,\n",
      "         -2.9875e-02,  4.6523e-01,  4.7995e-01, -5.5852e-01, -2.3887e-01,\n",
      "         -1.7665e-01,  5.7647e-01,  4.2711e-01,  2.3209e-01,  1.5230e-01,\n",
      "         -5.1227e-01, -2.6821e-01, -6.9349e-01, -2.4360e-01,  3.7202e-01,\n",
      "         -1.4729e-01,  6.3840e-01, -4.5381e-02, -3.1009e-01, -1.3489e-01,\n",
      "          3.0757e-01,  3.6232e-02, -6.5033e-01,  5.7968e-01,  6.9426e-01,\n",
      "          7.7915e-01,  2.3806e-01, -5.0545e-01, -4.0786e-01, -3.7224e-01,\n",
      "          2.9613e-01,  5.5267e-01,  5.3587e-01,  1.6533e-01, -3.2006e-01,\n",
      "          5.1221e-01, -2.4282e-01, -1.1892e-01, -4.4074e-02,  1.7182e-01,\n",
      "          5.3424e-01,  4.6433e-03, -6.2643e-01, -2.1724e-01,  2.5102e-01,\n",
      "          5.7839e-02,  3.9181e-01,  1.3969e-01,  4.6236e-01, -2.1800e-01,\n",
      "          2.7652e-01, -3.0023e-01,  1.4799e-01]], grad_fn=<TanhBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoImageProcessor, ViTModel\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"huggingface/cats-image\")\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "inputs = image_processor(image, return_tensors=\"pt\")\n",
    "\n",
    "print(\"output with original model: \\n\", model(**inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output with custom model: \n",
      " BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 0.1566,  0.0904,  0.1512,  ..., -0.3179, -0.0860, -0.0919],\n",
      "         [-0.2235,  0.0856,  0.4779,  ..., -0.1767,  0.1711,  0.1323],\n",
      "         [ 0.0449,  0.0681,  0.4221,  ..., -0.2572,  0.1173,  0.0126],\n",
      "         ...,\n",
      "         [-0.0152, -0.0393,  0.1688,  ..., -0.1690,  0.1859,  0.1011],\n",
      "         [ 0.0236, -0.0377,  0.2051,  ...,  0.0520,  0.1476,  0.1315],\n",
      "         [-0.1741, -0.0263,  0.2539,  ..., -0.1462,  0.1610,  0.1299]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 5.6516e-02, -3.0602e-01,  3.1479e-01, -1.1303e-01, -1.5046e-01,\n",
      "          4.9822e-01, -1.5958e-01,  4.8751e-01, -4.6317e-01,  2.4204e-01,\n",
      "          2.7707e-02,  2.8867e-01, -4.9035e-01, -1.0389e-02, -2.9009e-01,\n",
      "          3.1144e-01, -6.2464e-02, -2.6714e-01, -3.9563e-01,  3.0180e-01,\n",
      "          2.1344e-01, -1.9213e-01,  1.1921e-01,  2.5933e-01,  3.5225e-01,\n",
      "         -3.8258e-01,  4.8355e-01, -3.5428e-01,  2.4096e-01, -8.0840e-01,\n",
      "          1.1626e-02,  4.9710e-01,  6.9831e-01,  5.2750e-01,  6.8440e-01,\n",
      "          5.4116e-01, -3.6614e-01, -6.0726e-02,  2.2632e-01,  2.7138e-01,\n",
      "          4.5624e-01, -4.2577e-01, -4.5528e-02,  3.8043e-01,  1.1574e-01,\n",
      "         -6.0105e-01, -6.1104e-01, -2.8929e-01, -1.6159e-01, -2.2342e-01,\n",
      "          3.3233e-01, -4.6898e-01, -1.0918e-01, -1.8226e-01, -2.0249e-01,\n",
      "          1.6273e-01,  4.4715e-01,  3.1903e-01, -6.7778e-03,  2.4375e-01,\n",
      "          4.4313e-01, -4.5503e-01, -5.6617e-01, -1.7801e-01, -5.0368e-01,\n",
      "         -3.8737e-01, -6.2005e-02,  4.3011e-01,  3.6636e-01,  3.2490e-01,\n",
      "         -1.0638e-01, -1.0381e-01,  4.1968e-01,  2.8283e-01,  1.8761e-01,\n",
      "          3.0214e-01, -2.7530e-01,  7.6741e-02,  2.0464e-01,  4.0269e-01,\n",
      "          5.6512e-01, -4.3822e-01,  1.1158e-01, -3.3764e-01, -2.4642e-01,\n",
      "          5.0182e-01,  4.6024e-01,  1.6224e-02, -3.1387e-01, -4.3485e-01,\n",
      "          2.3946e-01, -6.9112e-01, -4.0592e-02, -4.1261e-01, -8.5643e-03,\n",
      "         -1.9185e-01, -4.0325e-01,  5.3288e-01, -1.0463e-01, -5.7641e-01,\n",
      "          9.0855e-02,  6.8352e-02, -1.8096e-01, -1.9919e-01,  1.9951e-01,\n",
      "         -1.5648e-01,  4.0059e-01, -8.5565e-02,  6.6178e-01, -1.6316e-01,\n",
      "          6.0242e-01,  2.7714e-01, -3.7503e-01, -6.1101e-01,  4.8640e-01,\n",
      "          5.2135e-01, -1.3273e-01,  2.1694e-01,  2.2040e-01, -4.4779e-01,\n",
      "         -3.0177e-01, -2.5116e-01,  3.7618e-02, -7.2561e-01,  2.2205e-01,\n",
      "          4.2117e-02, -3.3702e-01, -6.2808e-02,  1.4024e-02, -7.0653e-01,\n",
      "          2.0918e-01, -8.2476e-02, -2.2574e-01,  3.1464e-01, -6.5910e-01,\n",
      "         -2.0883e-01,  4.8574e-01, -3.8375e-01,  1.4682e-01, -4.9381e-01,\n",
      "          2.5770e-01,  1.6666e-01,  1.6630e-01, -7.9155e-01, -7.4177e-01,\n",
      "          1.0888e-02, -4.2982e-02,  1.5765e-01, -1.5343e-01,  3.5677e-01,\n",
      "          4.6375e-01, -2.4288e-01, -1.1606e-01, -2.9947e-01,  3.7857e-01,\n",
      "         -1.0918e-01,  2.4651e-02, -5.7756e-02, -5.7162e-02,  1.9849e-01,\n",
      "          5.0031e-02, -6.6103e-01, -3.3386e-01, -6.9859e-01, -9.6214e-02,\n",
      "          1.5461e-01, -6.0167e-01,  1.1740e-01, -5.8353e-01,  1.3654e-01,\n",
      "         -2.3053e-01, -2.2266e-01,  4.3053e-01, -8.9135e-03, -8.5173e-01,\n",
      "         -1.1490e-01, -2.6811e-01,  5.3474e-01,  3.4552e-01, -1.2384e-01,\n",
      "         -1.2114e-02,  3.8397e-01,  2.8567e-03,  4.7355e-01,  1.2748e-01,\n",
      "          1.4030e-01,  6.5288e-01,  3.4487e-01, -3.1039e-01, -4.7404e-01,\n",
      "         -5.0491e-01,  6.8834e-01, -1.1019e-01, -2.9220e-01,  1.1304e-01,\n",
      "          2.5788e-01, -1.6386e-01,  4.0551e-01,  2.7463e-01, -4.1553e-01,\n",
      "          2.1301e-01, -2.5227e-01,  2.7521e-01,  7.8102e-01,  3.2295e-01,\n",
      "          1.2192e-01,  1.6367e-01, -3.3165e-01,  1.3060e-01,  3.7798e-01,\n",
      "          6.4804e-01, -2.8840e-01, -1.9376e-01, -6.3365e-01,  4.4884e-01,\n",
      "         -3.5232e-01, -1.2236e-01,  4.5997e-01, -1.8106e-01, -3.4935e-01,\n",
      "         -1.9921e-01, -5.4064e-01,  4.0648e-01,  4.5250e-01,  2.3688e-01,\n",
      "         -5.7012e-01,  7.6924e-02,  5.4535e-01, -6.6565e-01, -1.7573e-01,\n",
      "         -4.6290e-01,  1.1174e-02, -1.2880e-01, -2.5340e-01, -1.2089e-01,\n",
      "          5.3572e-01, -2.5433e-02,  6.6063e-03, -7.1544e-01, -5.9405e-02,\n",
      "          3.5270e-02,  6.8923e-03,  4.1618e-01,  2.1488e-02,  1.2879e-01,\n",
      "          4.1012e-01, -5.7835e-02,  2.9995e-01,  5.4936e-02, -1.5466e-01,\n",
      "          7.4061e-01,  1.5418e-01,  7.4196e-02, -4.0104e-01,  8.8661e-02,\n",
      "          6.9823e-02,  1.4372e-01, -7.5201e-01, -3.7205e-01,  6.1983e-01,\n",
      "          4.1329e-01, -2.4977e-01,  4.1512e-01,  4.4710e-01, -8.3667e-02,\n",
      "         -6.5548e-01,  2.7247e-01,  1.6767e-01, -2.4205e-01,  1.0556e-01,\n",
      "          5.3528e-01,  6.6143e-01, -6.2444e-01, -3.4142e-01,  9.4886e-02,\n",
      "         -4.7829e-01,  2.9032e-01,  7.1139e-01,  1.5157e-01,  1.6122e-01,\n",
      "         -3.4159e-01,  4.0403e-01,  2.8062e-01,  1.5925e-01,  1.2450e-01,\n",
      "         -6.7149e-01,  9.8082e-02,  3.8645e-01,  6.2432e-01,  2.0752e-01,\n",
      "          2.4803e-01, -2.4539e-01, -4.0506e-01,  3.7878e-01,  7.7020e-02,\n",
      "         -1.3318e-01, -9.7283e-02,  4.3328e-02, -2.2362e-01,  3.6423e-01,\n",
      "          6.6761e-01,  2.0463e-01,  9.1304e-02,  5.5391e-03,  4.3894e-01,\n",
      "         -5.0242e-01, -3.3371e-01,  2.0836e-01,  1.2219e-01,  2.4386e-01,\n",
      "          7.5868e-01,  6.7440e-01,  3.6665e-01, -2.9233e-01,  1.4302e-01,\n",
      "          9.4579e-02,  5.1852e-01,  2.1510e-01,  6.7320e-01,  3.7340e-01,\n",
      "          4.5301e-01, -1.3195e-02, -1.3290e-01, -5.7327e-01,  2.2602e-01,\n",
      "         -1.8211e-01, -2.6281e-01,  2.7661e-01, -1.4503e-01,  3.3983e-01,\n",
      "         -6.9704e-01,  1.3373e-01, -1.8698e-02, -7.6685e-01,  5.7908e-01,\n",
      "          7.2314e-01,  5.8710e-02, -2.9368e-01, -3.1483e-01,  2.4162e-01,\n",
      "         -1.9847e-01,  3.3425e-01,  2.6525e-01,  4.5630e-01, -4.1540e-01,\n",
      "          7.2593e-01,  2.7318e-01,  7.6782e-01,  2.6399e-01, -3.8443e-01,\n",
      "         -7.2626e-02, -2.0930e-02,  3.1014e-01, -2.5713e-02,  1.0325e-01,\n",
      "          3.1223e-01,  1.3206e-02,  1.2948e-01,  7.2555e-02,  6.7436e-02,\n",
      "         -8.2178e-01, -2.2305e-01, -5.0335e-01,  6.5159e-02, -3.8268e-01,\n",
      "         -1.4163e-01,  2.4168e-01, -1.6159e-01,  1.5541e-01, -3.6819e-01,\n",
      "         -5.6318e-02,  4.3541e-01,  1.0767e-01,  3.8785e-01, -3.7096e-01,\n",
      "         -5.8535e-01,  3.6437e-01,  1.7476e-01, -7.1697e-02, -2.6993e-01,\n",
      "          3.3934e-01, -1.7144e-02,  9.2957e-02,  3.0461e-01,  2.0072e-01,\n",
      "          2.3264e-01,  4.0440e-01, -7.9819e-01, -1.8450e-01, -3.8843e-01,\n",
      "         -7.6884e-01,  1.3840e-01,  1.7371e-01,  5.1335e-01,  1.2499e-01,\n",
      "          2.1602e-01, -2.9742e-01,  7.4926e-02, -4.3213e-01, -5.5362e-01,\n",
      "          3.7057e-01, -3.4017e-02,  3.9499e-01,  7.3412e-01, -2.1905e-01,\n",
      "          1.0482e-01, -9.5094e-01, -3.3107e-02,  7.3080e-02,  4.1221e-01,\n",
      "          1.7310e-01, -4.1507e-01,  5.2902e-01, -2.1033e-01,  1.0153e-02,\n",
      "         -7.7803e-02, -3.1502e-01,  6.8658e-01, -2.9272e-01,  1.0562e-01,\n",
      "          2.1330e-01,  5.9685e-01, -3.9560e-01, -6.7811e-03,  6.8147e-01,\n",
      "         -2.8428e-01,  2.2385e-01,  5.5714e-01,  2.2932e-01,  6.6310e-01,\n",
      "          2.4458e-01, -6.2449e-02,  2.9543e-01,  2.9487e-01,  1.3535e-01,\n",
      "          6.6185e-02,  3.6352e-01,  6.5717e-01, -3.4022e-02,  5.4185e-01,\n",
      "          3.2999e-01, -3.7533e-01, -4.6214e-01,  9.4391e-02,  3.6200e-01,\n",
      "          1.1473e-01,  2.6088e-01,  1.7664e-01, -1.5738e-01,  6.6970e-02,\n",
      "          1.4356e-01, -3.2182e-01, -8.3300e-02, -3.2603e-01, -5.1688e-01,\n",
      "          5.7553e-01,  5.5144e-01, -4.9252e-01, -1.5163e-01, -5.8605e-01,\n",
      "          1.4151e-01, -1.6752e-01, -6.1914e-01,  3.8260e-01,  3.2222e-01,\n",
      "          5.6043e-01,  4.3192e-01,  4.4031e-01, -7.0699e-02, -2.8312e-01,\n",
      "          4.7025e-01,  2.8833e-01,  4.9985e-02,  6.2064e-02,  6.3278e-01,\n",
      "         -4.5969e-01,  7.7642e-02, -1.4585e-01,  3.1110e-01,  4.9309e-01,\n",
      "          2.1919e-01, -3.4610e-01,  1.4777e-01, -3.3246e-01,  2.7946e-01,\n",
      "          1.2461e-01, -2.3365e-02, -6.8827e-01,  3.7757e-01,  1.8415e-01,\n",
      "          3.7222e-01, -1.4392e-01, -3.3643e-01, -2.7931e-01,  3.7038e-01,\n",
      "          6.9785e-01, -5.2956e-01,  2.4677e-01,  1.2420e-01,  9.0254e-02,\n",
      "         -1.3665e-01, -1.9336e-02, -3.8227e-01,  6.8843e-01, -4.2290e-02,\n",
      "         -3.8240e-01,  2.4362e-01, -1.8070e-02, -4.5013e-01, -3.6956e-01,\n",
      "          4.2558e-01,  4.3542e-01,  2.8170e-01,  5.0036e-01,  5.7201e-01,\n",
      "         -9.9079e-02, -3.7411e-01, -5.7195e-01,  5.0840e-01, -2.3565e-01,\n",
      "         -8.3928e-01, -6.6737e-01, -6.9460e-01, -4.3771e-01, -7.1534e-01,\n",
      "         -4.9384e-01,  3.2389e-01, -2.6323e-01, -3.7182e-01,  3.9079e-01,\n",
      "          3.4001e-01, -2.1081e-01,  2.2511e-01,  2.0804e-01,  2.7870e-01,\n",
      "         -4.1183e-01, -4.5484e-01, -2.5002e-01,  5.3698e-01, -2.9551e-01,\n",
      "         -1.5812e-02, -4.0155e-01, -1.9275e-01,  4.7144e-02,  2.2610e-01,\n",
      "         -3.3732e-01, -2.5072e-01,  7.6005e-01, -2.0488e-01, -6.3582e-01,\n",
      "          5.3975e-01, -4.4086e-02, -4.7905e-01,  7.1882e-01, -8.5451e-01,\n",
      "          3.1460e-03, -6.0861e-01, -2.1963e-01,  4.4403e-01,  2.9082e-02,\n",
      "         -9.7619e-02, -3.7136e-02,  1.4363e-01,  9.4337e-02, -6.1195e-01,\n",
      "          6.6404e-01, -5.2408e-01,  2.0075e-01, -2.7125e-01,  3.6601e-01,\n",
      "         -4.7329e-01, -1.5844e-01, -6.2026e-01,  2.6613e-01,  7.1442e-01,\n",
      "         -6.2663e-02,  4.1300e-02, -5.0857e-01,  4.8709e-01, -3.7331e-03,\n",
      "          1.7445e-01, -7.4800e-01,  7.0618e-02, -1.8036e-01,  6.0469e-01,\n",
      "         -2.5887e-01, -1.3227e-01, -5.9857e-01,  3.0512e-01,  4.0598e-01,\n",
      "         -3.5775e-04, -3.1604e-01, -5.9184e-01,  6.0612e-01, -2.1775e-01,\n",
      "          5.0209e-02,  3.0921e-01,  2.0947e-01, -5.6798e-01,  4.7970e-01,\n",
      "          8.1546e-02,  7.7125e-01, -5.3852e-01, -2.1454e-01,  2.2297e-01,\n",
      "         -5.8241e-02,  2.7019e-01, -4.8473e-01, -2.8622e-02,  5.8001e-01,\n",
      "          1.3050e-02, -1.1960e-01,  4.8320e-01,  4.1732e-01, -2.3765e-01,\n",
      "         -2.2177e-01,  4.0304e-01,  2.6684e-01,  4.6376e-01,  2.0431e-01,\n",
      "          3.4040e-01, -6.3883e-01, -1.1908e-01, -2.9418e-01, -2.0185e-01,\n",
      "         -6.5296e-01,  6.5335e-01, -3.5211e-01,  3.6641e-01,  1.8494e-01,\n",
      "          3.8580e-03, -7.4842e-01, -9.9024e-01, -3.7191e-01, -3.2108e-01,\n",
      "          1.3557e-02,  1.2316e-01, -3.5669e-01, -4.5064e-01,  1.5580e-01,\n",
      "         -7.4188e-02,  5.1993e-01, -5.6288e-01,  2.8274e-01, -4.6714e-01,\n",
      "         -3.7087e-02, -2.7516e-01, -5.6605e-01,  5.5145e-01, -5.7469e-01,\n",
      "          2.7041e-01,  4.4822e-01, -1.5474e-01,  1.7039e-01, -3.0379e-01,\n",
      "          2.4653e-01,  2.1594e-01, -4.1643e-01, -1.9793e-01,  2.2986e-01,\n",
      "          1.6555e-02,  4.9837e-01,  1.0977e-01,  2.9511e-01, -1.4014e-01,\n",
      "          7.0349e-01, -5.1463e-01, -2.3127e-01, -5.0141e-01,  2.3763e-01,\n",
      "         -5.8033e-02, -6.7145e-01, -1.3293e-01,  4.3672e-02,  2.3941e-01,\n",
      "         -1.1637e-01,  3.9884e-01, -3.8860e-01,  2.2411e-01, -3.4402e-01,\n",
      "         -2.7761e-01,  4.5467e-01, -6.4332e-01, -2.5123e-01,  4.3472e-01,\n",
      "         -1.6740e-01,  3.7122e-01,  6.4627e-01, -1.0280e-01,  4.1511e-01,\n",
      "         -1.4717e-01,  5.8863e-01,  2.3425e-02,  2.4100e-01, -3.8341e-02,\n",
      "         -1.6118e-01, -5.8422e-01,  3.0621e-01,  2.2319e-01,  2.4262e-01,\n",
      "         -5.1806e-01, -2.6225e-01, -1.8920e-01, -6.0969e-01, -1.1068e-02,\n",
      "         -5.6098e-01, -1.1592e-01, -1.8177e-01,  3.4874e-01,  5.1328e-01,\n",
      "         -2.1923e-01,  1.4837e-02,  4.1523e-02,  6.8077e-02,  4.7320e-01,\n",
      "         -2.6868e-02,  4.6571e-01,  4.7902e-01, -5.5877e-01, -2.3966e-01,\n",
      "         -1.7769e-01,  5.7638e-01,  4.2587e-01,  2.3212e-01,  1.4816e-01,\n",
      "         -5.1420e-01, -2.6763e-01, -6.9351e-01, -2.4260e-01,  3.7136e-01,\n",
      "         -1.4487e-01,  6.3935e-01, -4.6016e-02, -3.1237e-01, -1.3684e-01,\n",
      "          3.0640e-01,  3.4148e-02, -6.5212e-01,  5.7965e-01,  6.9353e-01,\n",
      "          7.7969e-01,  2.3668e-01, -5.0599e-01, -4.0710e-01, -3.6942e-01,\n",
      "          2.9499e-01,  5.5235e-01,  5.3546e-01,  1.6202e-01, -3.1991e-01,\n",
      "          5.1386e-01, -2.4383e-01, -1.1830e-01, -4.6633e-02,  1.7152e-01,\n",
      "          5.3474e-01,  5.4200e-03, -6.2613e-01, -2.1860e-01,  2.5265e-01,\n",
      "          6.2212e-02,  3.9232e-01,  1.4039e-01,  4.6372e-01, -2.1808e-01,\n",
      "          2.7631e-01, -3.0022e-01,  1.4697e-01]], grad_fn=<TanhBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "import vit_optimizer\n",
    "\n",
    "# do encoder fusion\n",
    "vit_optimizer.optimize_bert_encoder(model)\n",
    "print(\"output with custom model: \\n\", model(**inputs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Int8 encoder fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: cats-image/image\n",
      "Found cached dataset cats-image (/home/marvin/.cache/huggingface/datasets/huggingface___cats-image/image/1.9.0/68fbc793fb10cd165e490867f5d61fa366086ea40c73e549a020103dcb4f597e)\n",
      "100%|██████████| 1/1 [00:00<00:00, 812.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output with original int8 model: \n",
      " BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 0.0671,  0.0577,  0.1704,  ..., -0.2897, -0.0215, -0.1593],\n",
      "         [-0.1750,  0.1396,  0.4689,  ..., -0.2322,  0.2679,  0.2359],\n",
      "         [ 0.0272,  0.1598,  0.4527,  ..., -0.2294,  0.1809,  0.1539],\n",
      "         ...,\n",
      "         [ 0.1208, -0.0062,  0.2898,  ..., -0.1514,  0.1938,  0.0468],\n",
      "         [-0.0377, -0.0633,  0.1613,  ..., -0.1985,  0.0992,  0.2628],\n",
      "         [-0.1818, -0.0094,  0.2225,  ..., -0.2125,  0.1303,  0.1951]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-1.6607e-01, -2.5335e-01,  2.7456e-01,  1.9225e-01, -8.4645e-02,\n",
      "          4.7062e-01, -1.2369e-01,  4.2519e-01, -6.2605e-01,  2.7125e-01,\n",
      "          5.8259e-02,  3.5742e-01, -4.4340e-01, -6.6103e-02, -2.4886e-01,\n",
      "          8.0751e-03,  1.0978e-01, -2.5643e-01, -3.0650e-01,  4.2634e-01,\n",
      "          2.0308e-01, -1.0710e-01,  1.5625e-01,  4.5200e-01,  3.6681e-01,\n",
      "         -4.1965e-01,  3.2702e-01, -2.4375e-01,  3.4988e-01, -7.2722e-01,\n",
      "         -1.2562e-01,  4.7606e-01,  7.3177e-01,  5.1379e-01,  6.5429e-01,\n",
      "          5.3781e-01, -2.9581e-01, -5.7848e-02,  2.4294e-01,  3.1373e-01,\n",
      "          4.9011e-01, -3.8523e-01, -4.5430e-02,  3.9077e-01, -3.0311e-02,\n",
      "         -5.0417e-01, -6.0830e-01, -4.1424e-01, -2.4824e-01, -1.5286e-01,\n",
      "          2.9059e-01, -4.6415e-01, -1.6627e-01, -1.7189e-01, -1.4259e-01,\n",
      "          6.0674e-02,  3.5544e-01,  3.3528e-01, -6.0773e-02,  3.2447e-01,\n",
      "          3.3396e-01, -4.7452e-01, -4.6423e-01, -1.9831e-03, -3.4313e-01,\n",
      "         -3.0903e-01,  1.0759e-01,  3.9858e-01,  3.2558e-01,  3.1388e-01,\n",
      "         -4.2850e-03, -5.8837e-02,  4.9110e-01,  1.8432e-01,  1.3443e-01,\n",
      "          2.4350e-01, -3.1915e-01, -7.1125e-02,  1.6026e-01,  4.3363e-01,\n",
      "          5.0337e-01, -2.7661e-01,  1.3905e-01, -1.4157e-01, -3.1771e-01,\n",
      "          4.7215e-01,  3.2066e-01,  9.5956e-02, -1.9771e-01, -4.8124e-01,\n",
      "          1.4456e-01, -5.7017e-01, -1.1318e-01, -4.8217e-01, -6.6951e-02,\n",
      "         -2.1902e-01, -2.6332e-01,  4.5953e-01, -1.3378e-01, -5.1801e-01,\n",
      "          1.4194e-01,  1.6508e-01, -7.4296e-02, -2.1787e-01,  1.2358e-01,\n",
      "         -1.6599e-01,  2.7226e-01, -2.4222e-01,  6.9726e-01, -2.6431e-01,\n",
      "          5.6068e-01,  9.6786e-02, -3.9717e-01, -6.7349e-01,  4.8851e-01,\n",
      "          5.1963e-01, -1.1606e-01,  7.3558e-02,  1.4692e-01, -4.3716e-01,\n",
      "         -7.5818e-02, -3.4182e-01,  5.2236e-02, -7.1411e-01,  2.9433e-01,\n",
      "         -4.9711e-02, -8.1834e-02,  7.1935e-02,  3.1497e-02, -6.8561e-01,\n",
      "          1.2160e-01,  8.0570e-02, -1.2975e-01,  3.5184e-01, -5.4521e-01,\n",
      "         -1.5946e-01,  4.7842e-01, -3.2181e-01, -1.4008e-01, -4.9439e-01,\n",
      "          2.2049e-01,  1.0080e-01,  2.9920e-01, -7.1321e-01, -7.8510e-01,\n",
      "          2.9542e-02,  1.6289e-01,  7.7871e-03, -3.1449e-01,  3.2618e-01,\n",
      "          4.7957e-01, -2.4332e-01, -6.5064e-02, -3.5030e-01,  5.4174e-01,\n",
      "         -1.1588e-01,  4.2471e-02,  5.2091e-02,  3.6307e-02,  2.0800e-01,\n",
      "          1.2610e-01, -5.6433e-01, -4.1851e-01, -5.9614e-01, -2.8870e-02,\n",
      "          1.4894e-01, -5.6534e-01,  1.3038e-01, -3.6323e-01,  2.3676e-01,\n",
      "         -1.5248e-01, -1.6847e-01,  2.8930e-01,  4.7497e-02, -8.3609e-01,\n",
      "         -1.8494e-01, -2.9214e-01,  3.2405e-01,  1.6910e-01,  6.2617e-02,\n",
      "         -2.7003e-02,  1.7463e-01, -7.5000e-02,  3.8853e-01,  1.8998e-01,\n",
      "          2.2704e-01,  5.3324e-01,  4.3158e-01, -2.7561e-01, -5.7926e-01,\n",
      "         -5.3916e-01,  7.6801e-01,  1.9494e-02, -3.2185e-01,  3.1676e-02,\n",
      "          7.4961e-02, -2.1683e-02,  3.0745e-01,  3.2525e-01, -3.2690e-01,\n",
      "          3.6368e-01, -4.3165e-01,  1.0852e-01,  7.5150e-01,  2.4714e-01,\n",
      "         -4.7515e-03,  3.5327e-01, -3.4274e-01, -1.3054e-02,  1.9814e-01,\n",
      "          4.6694e-01, -3.0666e-01, -2.2371e-01, -4.0000e-01,  3.0093e-01,\n",
      "         -2.3358e-01, -2.3172e-03,  4.0762e-01, -1.1815e-01, -2.4994e-01,\n",
      "          9.6922e-02, -4.8379e-01,  2.3417e-01,  3.3771e-01,  8.8526e-02,\n",
      "         -5.5787e-01,  3.9320e-02,  5.3602e-01, -6.0675e-01, -4.7523e-02,\n",
      "         -5.5829e-01,  2.0720e-01, -1.4022e-01, -3.9141e-01,  1.3880e-01,\n",
      "          5.7596e-01, -1.0717e-02,  4.8494e-02, -6.5470e-01, -1.1391e-02,\n",
      "         -3.4640e-02,  1.2156e-01,  3.4968e-01, -7.6203e-02, -7.0085e-02,\n",
      "          4.5353e-01, -5.5627e-02,  2.6450e-01,  1.8931e-02, -1.1658e-01,\n",
      "          7.4709e-01,  6.9562e-02,  2.8370e-02, -3.9394e-01,  1.7222e-01,\n",
      "          5.0673e-03,  8.3055e-02, -7.1067e-01,  2.5963e-02,  6.1381e-01,\n",
      "          4.4021e-01, -2.1926e-01,  2.9994e-01,  3.1554e-01, -1.6079e-01,\n",
      "         -7.2384e-01,  1.7744e-01,  1.4375e-01, -1.5525e-01,  2.3683e-01,\n",
      "          2.9014e-01,  7.0290e-01, -6.8438e-01, -3.5065e-01,  1.2267e-01,\n",
      "         -4.0731e-01,  3.3488e-01,  5.9555e-01,  1.2166e-01,  1.8709e-01,\n",
      "         -4.3805e-01,  4.3734e-01,  3.9540e-01,  2.1652e-02,  1.7690e-01,\n",
      "         -6.7043e-01, -8.7894e-03,  5.5682e-01,  6.0914e-01,  2.5934e-01,\n",
      "          2.2914e-01, -4.0423e-01, -2.9605e-01,  3.8553e-01,  3.1006e-02,\n",
      "         -2.3649e-01,  1.9232e-01,  1.0438e-01, -2.0228e-01,  3.5519e-01,\n",
      "          5.9484e-01,  1.6955e-01,  1.8529e-01,  4.1707e-02,  3.1597e-01,\n",
      "         -3.2793e-01, -2.1689e-01,  1.0129e-01,  2.9443e-01,  3.0729e-01,\n",
      "          7.0001e-01,  6.1246e-01,  2.8647e-01, -3.7251e-01,  1.2853e-01,\n",
      "          1.5175e-01,  5.0141e-01,  1.5060e-01,  6.6751e-01,  2.6784e-01,\n",
      "          4.3185e-01,  1.1313e-01, -4.2553e-02, -5.5101e-01,  1.5096e-01,\n",
      "         -1.8567e-01, -2.4761e-01,  2.4948e-01, -2.2055e-01,  5.3520e-01,\n",
      "         -5.1649e-01,  2.1599e-01,  2.6939e-02, -6.7101e-01,  5.6793e-01,\n",
      "          6.5791e-01, -7.0239e-02, -3.4284e-01, -3.0649e-01,  4.2071e-01,\n",
      "         -1.3386e-01,  2.6170e-01,  3.1740e-01,  5.6245e-01, -2.3894e-01,\n",
      "          7.4975e-01,  3.1200e-01,  6.9362e-01,  2.7312e-01, -3.1868e-01,\n",
      "         -1.7649e-01,  5.4188e-02,  1.4606e-01, -1.2119e-01,  2.0506e-01,\n",
      "          2.2789e-01,  2.2622e-01,  2.6537e-01,  1.0110e-01,  1.3317e-01,\n",
      "         -7.3495e-01, -2.7372e-01, -3.9105e-01, -1.1166e-01, -3.4778e-01,\n",
      "         -1.1790e-01,  2.2101e-01, -1.3583e-01,  2.6577e-01, -3.4728e-01,\n",
      "         -1.6993e-01,  5.4024e-01,  1.8342e-01,  3.8624e-01, -2.7231e-01,\n",
      "         -5.4345e-01,  2.0755e-01,  1.2739e-01,  2.8976e-02, -1.0134e-01,\n",
      "          4.7137e-01, -8.8780e-02,  7.7253e-02,  1.9904e-01,  3.2872e-01,\n",
      "          2.8840e-01,  3.1697e-01, -8.3718e-01, -1.8742e-01, -3.5741e-01,\n",
      "         -7.3917e-01,  3.0337e-01,  9.6513e-02,  5.6070e-01,  1.1211e-01,\n",
      "          7.3490e-02, -3.5490e-01,  1.3460e-01, -3.0629e-01, -4.6114e-01,\n",
      "          3.9775e-01, -3.4004e-02,  3.0343e-01,  7.4112e-01, -9.8429e-02,\n",
      "          5.6428e-02, -9.5050e-01,  6.5939e-02,  4.7089e-02,  3.1156e-01,\n",
      "          2.0306e-01, -5.4148e-01,  4.9533e-01, -2.1075e-01, -1.9656e-01,\n",
      "          9.1765e-02, -2.6141e-01,  6.1340e-01, -1.9176e-01,  2.2815e-01,\n",
      "          8.4839e-02,  5.3306e-01, -2.7982e-01,  3.1081e-01,  6.1002e-01,\n",
      "         -3.6014e-01,  7.8445e-02,  5.4349e-01,  2.7021e-01,  6.7461e-01,\n",
      "          1.0251e-01, -2.6366e-01,  3.1989e-01,  3.7383e-01,  3.3964e-01,\n",
      "          1.7973e-02,  3.4883e-01,  6.7479e-01, -1.0695e-01,  6.2395e-01,\n",
      "          3.0429e-01, -4.5873e-01, -4.7339e-01,  1.6572e-02,  2.4783e-01,\n",
      "         -8.2859e-02,  4.2913e-01,  2.5625e-01,  2.2668e-02,  1.0468e-01,\n",
      "          1.8539e-01, -3.6961e-01,  3.1175e-02, -2.1634e-01, -5.2325e-01,\n",
      "          5.1439e-01,  4.1180e-01, -3.5525e-01, -1.4392e-01, -5.0606e-01,\n",
      "          1.3594e-01, -7.3504e-02, -6.0752e-01,  2.3396e-01,  3.1982e-01,\n",
      "          4.6941e-01,  4.1598e-01,  3.1110e-01, -1.3500e-01, -1.7984e-01,\n",
      "          4.2184e-01,  4.1565e-01, -7.1549e-03, -4.7045e-02,  6.8735e-01,\n",
      "         -4.5690e-01,  6.9782e-02, -1.3131e-01,  2.2949e-01,  6.0875e-01,\n",
      "          1.3552e-02, -1.5583e-01, -1.7134e-02, -2.9689e-01,  3.1664e-01,\n",
      "          2.8844e-02,  1.2064e-01, -7.5971e-01,  4.5266e-01,  3.4287e-01,\n",
      "          3.8606e-01, -5.5974e-02, -3.7559e-01, -9.3094e-02,  3.7958e-01,\n",
      "          7.9620e-01, -6.3878e-01,  2.6397e-01,  1.5292e-01,  1.6225e-01,\n",
      "         -1.8045e-01, -1.3096e-01, -4.1024e-01,  7.7660e-01, -1.4976e-01,\n",
      "         -1.5178e-01,  5.0521e-02, -4.6516e-02, -4.2480e-01, -4.2659e-01,\n",
      "          3.5476e-01,  5.5448e-01,  2.2130e-01,  4.4968e-01,  5.0457e-01,\n",
      "         -2.8534e-01, -2.8926e-01, -5.1055e-01,  4.6465e-01, -1.2135e-01,\n",
      "         -8.1601e-01, -5.7555e-01, -6.2832e-01, -5.6039e-01, -6.4784e-01,\n",
      "         -4.5100e-01,  4.8639e-01, -2.5318e-01, -2.2681e-01,  4.0354e-01,\n",
      "          2.1701e-01, -1.5099e-01,  3.8222e-01,  1.3731e-01,  1.7555e-01,\n",
      "         -2.8271e-01, -6.0212e-01, -3.1354e-01,  4.9996e-01, -4.5591e-01,\n",
      "         -1.1838e-01, -3.8609e-01, -2.4629e-01,  1.3239e-01,  2.6326e-01,\n",
      "         -1.4044e-01, -2.9364e-01,  7.5818e-01, -2.3446e-01, -6.9116e-01,\n",
      "          3.4812e-01,  2.2410e-02, -4.4937e-01,  6.6334e-01, -7.5075e-01,\n",
      "         -1.2421e-01, -5.7886e-01, -3.1827e-01,  4.4315e-01, -4.4151e-02,\n",
      "         -1.1891e-01, -1.1218e-02,  2.4445e-01,  1.1709e-01, -5.0222e-01,\n",
      "          6.8895e-01, -5.9064e-01,  1.1271e-01, -3.9060e-01,  3.8767e-01,\n",
      "         -4.7271e-01, -2.6138e-01, -6.5317e-01,  2.8401e-01,  7.7503e-01,\n",
      "          6.4620e-02,  1.4004e-01, -4.0659e-01,  5.2963e-01,  7.9238e-03,\n",
      "          1.2190e-01, -6.1657e-01,  9.5472e-02, -9.4019e-02,  5.1411e-01,\n",
      "         -4.2191e-01, -2.6896e-01, -5.7117e-01,  2.8404e-02,  2.4755e-01,\n",
      "          1.1448e-01, -1.7779e-01, -3.4805e-01,  5.2970e-01, -8.3060e-02,\n",
      "         -5.2425e-03,  2.7334e-01,  2.7668e-01, -4.7650e-01,  4.7668e-01,\n",
      "          4.4003e-03,  7.9596e-01, -3.7419e-01, -2.8001e-01,  2.7328e-01,\n",
      "         -1.1332e-01,  2.4570e-01, -4.1196e-01,  6.1043e-02,  7.2745e-01,\n",
      "          1.2694e-01, -1.1457e-01,  4.7772e-01,  3.5459e-01, -1.7884e-01,\n",
      "         -2.0817e-01,  2.3457e-01,  1.4628e-01,  5.5730e-01,  1.7946e-01,\n",
      "          1.5884e-01, -6.0630e-01, -1.0531e-01, -2.6365e-01, -2.4560e-01,\n",
      "         -7.2650e-01,  5.2528e-01, -2.7553e-01,  4.2793e-01,  3.3125e-01,\n",
      "          2.3013e-01, -6.2869e-01, -9.9661e-01, -3.5220e-01, -2.4637e-01,\n",
      "          4.7107e-02,  9.2314e-02, -1.9668e-01, -5.4512e-01, -6.6194e-02,\n",
      "          6.1188e-03,  5.1358e-01, -6.5015e-01,  2.1713e-01, -4.2871e-01,\n",
      "          4.5107e-02, -1.6733e-01, -4.9304e-01,  5.3633e-01, -5.3447e-01,\n",
      "          1.9226e-01,  3.1251e-01, -1.0976e-01,  1.8524e-02, -3.8828e-01,\n",
      "          3.6032e-01,  2.9929e-01, -2.9582e-01, -1.6313e-01,  1.0982e-02,\n",
      "          2.3720e-01,  3.6939e-01,  9.1780e-02,  2.5053e-01, -2.4797e-01,\n",
      "          6.9917e-01, -4.3049e-01, -3.2579e-01, -3.2972e-01,  2.9230e-01,\n",
      "          5.7970e-04, -5.9640e-01, -1.5892e-01,  1.6712e-01,  1.2576e-01,\n",
      "         -2.7766e-02,  2.8102e-01, -2.7988e-01,  8.8604e-02, -6.9212e-02,\n",
      "         -1.7258e-01,  5.0510e-01, -6.7272e-01, -3.0393e-01,  4.4106e-01,\n",
      "         -2.2769e-01,  3.0744e-01,  7.4423e-01, -1.1833e-01,  3.5863e-01,\n",
      "         -3.9597e-01,  5.4743e-01,  8.7330e-02,  2.7574e-01, -1.8853e-01,\n",
      "         -4.5204e-02, -6.1719e-01,  2.3351e-01,  2.7498e-01, -6.3932e-02,\n",
      "         -3.5759e-01, -1.5385e-01, -3.3640e-01, -5.9922e-01,  6.1005e-02,\n",
      "         -4.9220e-01, -2.4620e-01, -5.5995e-02,  3.6426e-01,  4.1363e-01,\n",
      "         -1.1684e-01, -1.1916e-01,  5.9863e-02,  7.2999e-02,  4.6095e-01,\n",
      "          3.2931e-02,  2.8228e-01,  4.0155e-01, -4.8717e-01, -2.3147e-01,\n",
      "         -7.8233e-02,  5.3425e-01,  2.1300e-01,  5.1881e-02,  1.7038e-01,\n",
      "         -4.2859e-01, -4.1590e-01, -6.6688e-01, -3.4763e-01,  3.6621e-01,\n",
      "         -5.2971e-02,  6.6483e-01, -1.9932e-01, -3.8107e-01, -7.0565e-02,\n",
      "          2.5531e-01,  8.4095e-02, -6.7176e-01,  6.5527e-01,  5.7783e-01,\n",
      "          7.8006e-01,  4.5526e-02, -4.8352e-01, -2.6366e-01, -3.7383e-01,\n",
      "          3.6298e-01,  4.8035e-01,  6.2010e-01,  1.4121e-01, -2.4517e-01,\n",
      "          2.7908e-01, -1.9865e-01,  1.2263e-01, -1.5582e-01,  1.0492e-01,\n",
      "          5.1689e-01,  7.8391e-02, -5.2390e-01, -2.1262e-01,  4.5999e-01,\n",
      "         -1.2196e-02,  2.9107e-01,  1.5221e-01,  3.1753e-01, -3.0241e-01,\n",
      "          4.2142e-01, -3.2997e-01,  1.6677e-01]]), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# int8 quantization with encoder fusion\n",
    "\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, ViTModel\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"huggingface/cats-image\")\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "inputs = image_processor(image, return_tensors=\"pt\")\n",
    "\n",
    "# Dynamic quantization with PT\n",
    "q_model = torch.quantization.quantize_dynamic(model)\n",
    "\n",
    "print(\"output with original int8 model: \\n\", q_model(**inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output with custom int8 model: \n",
      " BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 0.0671,  0.0577,  0.1704,  ..., -0.2897, -0.0215, -0.1593],\n",
      "         [-0.1750,  0.1396,  0.4689,  ..., -0.2322,  0.2679,  0.2359],\n",
      "         [ 0.0272,  0.1598,  0.4527,  ..., -0.2294,  0.1809,  0.1539],\n",
      "         ...,\n",
      "         [ 0.1208, -0.0062,  0.2898,  ..., -0.1514,  0.1938,  0.0468],\n",
      "         [-0.0377, -0.0633,  0.1613,  ..., -0.1985,  0.0992,  0.2628],\n",
      "         [-0.1818, -0.0094,  0.2225,  ..., -0.2125,  0.1303,  0.1951]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-1.6607e-01, -2.5335e-01,  2.7456e-01,  1.9225e-01, -8.4645e-02,\n",
      "          4.7062e-01, -1.2369e-01,  4.2519e-01, -6.2605e-01,  2.7125e-01,\n",
      "          5.8259e-02,  3.5742e-01, -4.4340e-01, -6.6103e-02, -2.4886e-01,\n",
      "          8.0751e-03,  1.0978e-01, -2.5643e-01, -3.0650e-01,  4.2634e-01,\n",
      "          2.0308e-01, -1.0710e-01,  1.5625e-01,  4.5200e-01,  3.6681e-01,\n",
      "         -4.1965e-01,  3.2702e-01, -2.4375e-01,  3.4988e-01, -7.2722e-01,\n",
      "         -1.2562e-01,  4.7606e-01,  7.3177e-01,  5.1379e-01,  6.5429e-01,\n",
      "          5.3781e-01, -2.9581e-01, -5.7848e-02,  2.4294e-01,  3.1373e-01,\n",
      "          4.9011e-01, -3.8523e-01, -4.5430e-02,  3.9077e-01, -3.0311e-02,\n",
      "         -5.0417e-01, -6.0830e-01, -4.1424e-01, -2.4824e-01, -1.5286e-01,\n",
      "          2.9059e-01, -4.6415e-01, -1.6627e-01, -1.7189e-01, -1.4259e-01,\n",
      "          6.0674e-02,  3.5544e-01,  3.3528e-01, -6.0773e-02,  3.2447e-01,\n",
      "          3.3396e-01, -4.7452e-01, -4.6423e-01, -1.9831e-03, -3.4313e-01,\n",
      "         -3.0903e-01,  1.0759e-01,  3.9858e-01,  3.2558e-01,  3.1388e-01,\n",
      "         -4.2850e-03, -5.8837e-02,  4.9110e-01,  1.8432e-01,  1.3443e-01,\n",
      "          2.4350e-01, -3.1915e-01, -7.1125e-02,  1.6026e-01,  4.3363e-01,\n",
      "          5.0337e-01, -2.7661e-01,  1.3905e-01, -1.4157e-01, -3.1771e-01,\n",
      "          4.7215e-01,  3.2066e-01,  9.5956e-02, -1.9771e-01, -4.8124e-01,\n",
      "          1.4456e-01, -5.7017e-01, -1.1318e-01, -4.8217e-01, -6.6951e-02,\n",
      "         -2.1902e-01, -2.6332e-01,  4.5953e-01, -1.3378e-01, -5.1801e-01,\n",
      "          1.4194e-01,  1.6508e-01, -7.4296e-02, -2.1787e-01,  1.2358e-01,\n",
      "         -1.6599e-01,  2.7226e-01, -2.4222e-01,  6.9726e-01, -2.6431e-01,\n",
      "          5.6068e-01,  9.6786e-02, -3.9717e-01, -6.7349e-01,  4.8851e-01,\n",
      "          5.1963e-01, -1.1606e-01,  7.3558e-02,  1.4692e-01, -4.3716e-01,\n",
      "         -7.5818e-02, -3.4182e-01,  5.2236e-02, -7.1411e-01,  2.9433e-01,\n",
      "         -4.9711e-02, -8.1834e-02,  7.1935e-02,  3.1497e-02, -6.8561e-01,\n",
      "          1.2160e-01,  8.0570e-02, -1.2975e-01,  3.5184e-01, -5.4521e-01,\n",
      "         -1.5946e-01,  4.7842e-01, -3.2181e-01, -1.4008e-01, -4.9439e-01,\n",
      "          2.2049e-01,  1.0080e-01,  2.9920e-01, -7.1321e-01, -7.8510e-01,\n",
      "          2.9542e-02,  1.6289e-01,  7.7871e-03, -3.1449e-01,  3.2618e-01,\n",
      "          4.7957e-01, -2.4332e-01, -6.5064e-02, -3.5030e-01,  5.4174e-01,\n",
      "         -1.1588e-01,  4.2471e-02,  5.2091e-02,  3.6307e-02,  2.0800e-01,\n",
      "          1.2610e-01, -5.6433e-01, -4.1851e-01, -5.9614e-01, -2.8870e-02,\n",
      "          1.4894e-01, -5.6534e-01,  1.3038e-01, -3.6323e-01,  2.3676e-01,\n",
      "         -1.5248e-01, -1.6847e-01,  2.8930e-01,  4.7497e-02, -8.3609e-01,\n",
      "         -1.8494e-01, -2.9214e-01,  3.2405e-01,  1.6910e-01,  6.2617e-02,\n",
      "         -2.7003e-02,  1.7463e-01, -7.5000e-02,  3.8853e-01,  1.8998e-01,\n",
      "          2.2704e-01,  5.3324e-01,  4.3158e-01, -2.7561e-01, -5.7926e-01,\n",
      "         -5.3916e-01,  7.6801e-01,  1.9494e-02, -3.2185e-01,  3.1676e-02,\n",
      "          7.4961e-02, -2.1683e-02,  3.0745e-01,  3.2525e-01, -3.2690e-01,\n",
      "          3.6368e-01, -4.3165e-01,  1.0852e-01,  7.5150e-01,  2.4714e-01,\n",
      "         -4.7515e-03,  3.5327e-01, -3.4274e-01, -1.3054e-02,  1.9814e-01,\n",
      "          4.6694e-01, -3.0666e-01, -2.2371e-01, -4.0000e-01,  3.0093e-01,\n",
      "         -2.3358e-01, -2.3172e-03,  4.0762e-01, -1.1815e-01, -2.4994e-01,\n",
      "          9.6922e-02, -4.8379e-01,  2.3417e-01,  3.3771e-01,  8.8526e-02,\n",
      "         -5.5787e-01,  3.9320e-02,  5.3602e-01, -6.0675e-01, -4.7523e-02,\n",
      "         -5.5829e-01,  2.0720e-01, -1.4022e-01, -3.9141e-01,  1.3880e-01,\n",
      "          5.7596e-01, -1.0717e-02,  4.8494e-02, -6.5470e-01, -1.1391e-02,\n",
      "         -3.4640e-02,  1.2156e-01,  3.4968e-01, -7.6203e-02, -7.0085e-02,\n",
      "          4.5353e-01, -5.5627e-02,  2.6450e-01,  1.8931e-02, -1.1658e-01,\n",
      "          7.4709e-01,  6.9562e-02,  2.8370e-02, -3.9394e-01,  1.7222e-01,\n",
      "          5.0673e-03,  8.3055e-02, -7.1067e-01,  2.5963e-02,  6.1381e-01,\n",
      "          4.4021e-01, -2.1926e-01,  2.9994e-01,  3.1554e-01, -1.6079e-01,\n",
      "         -7.2384e-01,  1.7744e-01,  1.4375e-01, -1.5525e-01,  2.3683e-01,\n",
      "          2.9014e-01,  7.0290e-01, -6.8438e-01, -3.5065e-01,  1.2267e-01,\n",
      "         -4.0731e-01,  3.3488e-01,  5.9555e-01,  1.2166e-01,  1.8709e-01,\n",
      "         -4.3805e-01,  4.3734e-01,  3.9540e-01,  2.1652e-02,  1.7690e-01,\n",
      "         -6.7043e-01, -8.7894e-03,  5.5682e-01,  6.0914e-01,  2.5934e-01,\n",
      "          2.2914e-01, -4.0423e-01, -2.9605e-01,  3.8553e-01,  3.1006e-02,\n",
      "         -2.3649e-01,  1.9232e-01,  1.0438e-01, -2.0228e-01,  3.5519e-01,\n",
      "          5.9484e-01,  1.6955e-01,  1.8529e-01,  4.1707e-02,  3.1597e-01,\n",
      "         -3.2793e-01, -2.1689e-01,  1.0129e-01,  2.9443e-01,  3.0729e-01,\n",
      "          7.0001e-01,  6.1246e-01,  2.8647e-01, -3.7251e-01,  1.2853e-01,\n",
      "          1.5175e-01,  5.0141e-01,  1.5060e-01,  6.6751e-01,  2.6784e-01,\n",
      "          4.3185e-01,  1.1313e-01, -4.2553e-02, -5.5101e-01,  1.5096e-01,\n",
      "         -1.8567e-01, -2.4761e-01,  2.4948e-01, -2.2055e-01,  5.3520e-01,\n",
      "         -5.1649e-01,  2.1599e-01,  2.6939e-02, -6.7101e-01,  5.6793e-01,\n",
      "          6.5791e-01, -7.0239e-02, -3.4284e-01, -3.0649e-01,  4.2071e-01,\n",
      "         -1.3386e-01,  2.6170e-01,  3.1740e-01,  5.6245e-01, -2.3894e-01,\n",
      "          7.4975e-01,  3.1200e-01,  6.9362e-01,  2.7312e-01, -3.1868e-01,\n",
      "         -1.7649e-01,  5.4188e-02,  1.4606e-01, -1.2119e-01,  2.0506e-01,\n",
      "          2.2789e-01,  2.2622e-01,  2.6537e-01,  1.0110e-01,  1.3317e-01,\n",
      "         -7.3495e-01, -2.7372e-01, -3.9105e-01, -1.1166e-01, -3.4778e-01,\n",
      "         -1.1790e-01,  2.2101e-01, -1.3583e-01,  2.6577e-01, -3.4728e-01,\n",
      "         -1.6993e-01,  5.4024e-01,  1.8342e-01,  3.8624e-01, -2.7231e-01,\n",
      "         -5.4345e-01,  2.0755e-01,  1.2739e-01,  2.8976e-02, -1.0134e-01,\n",
      "          4.7137e-01, -8.8780e-02,  7.7253e-02,  1.9904e-01,  3.2872e-01,\n",
      "          2.8840e-01,  3.1697e-01, -8.3718e-01, -1.8742e-01, -3.5741e-01,\n",
      "         -7.3917e-01,  3.0337e-01,  9.6513e-02,  5.6070e-01,  1.1211e-01,\n",
      "          7.3490e-02, -3.5490e-01,  1.3460e-01, -3.0629e-01, -4.6114e-01,\n",
      "          3.9775e-01, -3.4004e-02,  3.0343e-01,  7.4112e-01, -9.8429e-02,\n",
      "          5.6428e-02, -9.5050e-01,  6.5939e-02,  4.7089e-02,  3.1156e-01,\n",
      "          2.0306e-01, -5.4148e-01,  4.9533e-01, -2.1075e-01, -1.9656e-01,\n",
      "          9.1765e-02, -2.6141e-01,  6.1340e-01, -1.9176e-01,  2.2815e-01,\n",
      "          8.4839e-02,  5.3306e-01, -2.7982e-01,  3.1081e-01,  6.1002e-01,\n",
      "         -3.6014e-01,  7.8445e-02,  5.4349e-01,  2.7021e-01,  6.7461e-01,\n",
      "          1.0251e-01, -2.6366e-01,  3.1989e-01,  3.7383e-01,  3.3964e-01,\n",
      "          1.7973e-02,  3.4883e-01,  6.7479e-01, -1.0695e-01,  6.2395e-01,\n",
      "          3.0429e-01, -4.5873e-01, -4.7339e-01,  1.6572e-02,  2.4783e-01,\n",
      "         -8.2859e-02,  4.2913e-01,  2.5625e-01,  2.2668e-02,  1.0468e-01,\n",
      "          1.8539e-01, -3.6961e-01,  3.1175e-02, -2.1634e-01, -5.2325e-01,\n",
      "          5.1439e-01,  4.1180e-01, -3.5525e-01, -1.4392e-01, -5.0606e-01,\n",
      "          1.3594e-01, -7.3504e-02, -6.0752e-01,  2.3396e-01,  3.1982e-01,\n",
      "          4.6941e-01,  4.1598e-01,  3.1110e-01, -1.3500e-01, -1.7984e-01,\n",
      "          4.2184e-01,  4.1565e-01, -7.1549e-03, -4.7045e-02,  6.8735e-01,\n",
      "         -4.5690e-01,  6.9782e-02, -1.3131e-01,  2.2949e-01,  6.0875e-01,\n",
      "          1.3552e-02, -1.5583e-01, -1.7134e-02, -2.9689e-01,  3.1664e-01,\n",
      "          2.8844e-02,  1.2064e-01, -7.5971e-01,  4.5266e-01,  3.4287e-01,\n",
      "          3.8606e-01, -5.5974e-02, -3.7559e-01, -9.3094e-02,  3.7958e-01,\n",
      "          7.9620e-01, -6.3878e-01,  2.6397e-01,  1.5292e-01,  1.6225e-01,\n",
      "         -1.8045e-01, -1.3096e-01, -4.1024e-01,  7.7660e-01, -1.4976e-01,\n",
      "         -1.5178e-01,  5.0521e-02, -4.6516e-02, -4.2480e-01, -4.2659e-01,\n",
      "          3.5476e-01,  5.5448e-01,  2.2130e-01,  4.4968e-01,  5.0457e-01,\n",
      "         -2.8534e-01, -2.8926e-01, -5.1055e-01,  4.6465e-01, -1.2135e-01,\n",
      "         -8.1601e-01, -5.7555e-01, -6.2832e-01, -5.6039e-01, -6.4784e-01,\n",
      "         -4.5100e-01,  4.8639e-01, -2.5318e-01, -2.2681e-01,  4.0354e-01,\n",
      "          2.1701e-01, -1.5099e-01,  3.8222e-01,  1.3731e-01,  1.7555e-01,\n",
      "         -2.8271e-01, -6.0212e-01, -3.1354e-01,  4.9996e-01, -4.5591e-01,\n",
      "         -1.1838e-01, -3.8609e-01, -2.4629e-01,  1.3239e-01,  2.6326e-01,\n",
      "         -1.4044e-01, -2.9364e-01,  7.5818e-01, -2.3446e-01, -6.9116e-01,\n",
      "          3.4812e-01,  2.2410e-02, -4.4937e-01,  6.6334e-01, -7.5075e-01,\n",
      "         -1.2421e-01, -5.7886e-01, -3.1827e-01,  4.4315e-01, -4.4151e-02,\n",
      "         -1.1891e-01, -1.1218e-02,  2.4445e-01,  1.1709e-01, -5.0222e-01,\n",
      "          6.8895e-01, -5.9064e-01,  1.1271e-01, -3.9060e-01,  3.8767e-01,\n",
      "         -4.7271e-01, -2.6138e-01, -6.5317e-01,  2.8401e-01,  7.7503e-01,\n",
      "          6.4620e-02,  1.4004e-01, -4.0659e-01,  5.2963e-01,  7.9238e-03,\n",
      "          1.2190e-01, -6.1657e-01,  9.5472e-02, -9.4019e-02,  5.1411e-01,\n",
      "         -4.2191e-01, -2.6896e-01, -5.7117e-01,  2.8404e-02,  2.4755e-01,\n",
      "          1.1448e-01, -1.7779e-01, -3.4805e-01,  5.2970e-01, -8.3060e-02,\n",
      "         -5.2425e-03,  2.7334e-01,  2.7668e-01, -4.7650e-01,  4.7668e-01,\n",
      "          4.4003e-03,  7.9596e-01, -3.7419e-01, -2.8001e-01,  2.7328e-01,\n",
      "         -1.1332e-01,  2.4570e-01, -4.1196e-01,  6.1043e-02,  7.2745e-01,\n",
      "          1.2694e-01, -1.1457e-01,  4.7772e-01,  3.5459e-01, -1.7884e-01,\n",
      "         -2.0817e-01,  2.3457e-01,  1.4628e-01,  5.5730e-01,  1.7946e-01,\n",
      "          1.5884e-01, -6.0630e-01, -1.0531e-01, -2.6365e-01, -2.4560e-01,\n",
      "         -7.2650e-01,  5.2528e-01, -2.7553e-01,  4.2793e-01,  3.3125e-01,\n",
      "          2.3013e-01, -6.2869e-01, -9.9661e-01, -3.5220e-01, -2.4637e-01,\n",
      "          4.7107e-02,  9.2314e-02, -1.9668e-01, -5.4512e-01, -6.6194e-02,\n",
      "          6.1188e-03,  5.1358e-01, -6.5015e-01,  2.1713e-01, -4.2871e-01,\n",
      "          4.5107e-02, -1.6733e-01, -4.9304e-01,  5.3633e-01, -5.3447e-01,\n",
      "          1.9226e-01,  3.1251e-01, -1.0976e-01,  1.8524e-02, -3.8828e-01,\n",
      "          3.6032e-01,  2.9929e-01, -2.9582e-01, -1.6313e-01,  1.0982e-02,\n",
      "          2.3720e-01,  3.6939e-01,  9.1780e-02,  2.5053e-01, -2.4797e-01,\n",
      "          6.9917e-01, -4.3049e-01, -3.2579e-01, -3.2972e-01,  2.9230e-01,\n",
      "          5.7970e-04, -5.9640e-01, -1.5892e-01,  1.6712e-01,  1.2576e-01,\n",
      "         -2.7766e-02,  2.8102e-01, -2.7988e-01,  8.8604e-02, -6.9212e-02,\n",
      "         -1.7258e-01,  5.0510e-01, -6.7272e-01, -3.0393e-01,  4.4106e-01,\n",
      "         -2.2769e-01,  3.0744e-01,  7.4423e-01, -1.1833e-01,  3.5863e-01,\n",
      "         -3.9597e-01,  5.4743e-01,  8.7330e-02,  2.7574e-01, -1.8853e-01,\n",
      "         -4.5204e-02, -6.1719e-01,  2.3351e-01,  2.7498e-01, -6.3932e-02,\n",
      "         -3.5759e-01, -1.5385e-01, -3.3640e-01, -5.9922e-01,  6.1005e-02,\n",
      "         -4.9220e-01, -2.4620e-01, -5.5995e-02,  3.6426e-01,  4.1363e-01,\n",
      "         -1.1684e-01, -1.1916e-01,  5.9863e-02,  7.2999e-02,  4.6095e-01,\n",
      "          3.2931e-02,  2.8228e-01,  4.0155e-01, -4.8717e-01, -2.3147e-01,\n",
      "         -7.8233e-02,  5.3425e-01,  2.1300e-01,  5.1881e-02,  1.7038e-01,\n",
      "         -4.2859e-01, -4.1590e-01, -6.6688e-01, -3.4763e-01,  3.6621e-01,\n",
      "         -5.2971e-02,  6.6483e-01, -1.9932e-01, -3.8107e-01, -7.0565e-02,\n",
      "          2.5531e-01,  8.4095e-02, -6.7176e-01,  6.5527e-01,  5.7783e-01,\n",
      "          7.8006e-01,  4.5526e-02, -4.8352e-01, -2.6366e-01, -3.7383e-01,\n",
      "          3.6298e-01,  4.8035e-01,  6.2010e-01,  1.4121e-01, -2.4517e-01,\n",
      "          2.7908e-01, -1.9865e-01,  1.2263e-01, -1.5582e-01,  1.0492e-01,\n",
      "          5.1689e-01,  7.8391e-02, -5.2390e-01, -2.1262e-01,  4.5999e-01,\n",
      "         -1.2196e-02,  2.9107e-01,  1.5221e-01,  3.1753e-01, -3.0241e-01,\n",
      "          4.2142e-01, -3.2997e-01,  1.6677e-01]]), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import vit_optimizer\n",
    "vit_optimizer.optimize_bert_encoder(model, is_int8=True)\n",
    "\n",
    "# Dynamic quantization with PT\n",
    "model = torch.quantization.quantize_dynamic(model)\n",
    "\n",
    "print(\"output with custom int8 model: \\n\", q_model(**inputs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
